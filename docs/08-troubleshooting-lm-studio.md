# LM Studio ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

## ğŸ”´ ë°œìƒí•œ ì—ëŸ¬ ë¶„ì„

### ì—ëŸ¬ ìœ í˜•

#### 1. Model Crash (Exit Code 11)
```
Error code: 400 - {'error': 'The model has crashed without additional information. (Exit code: 11)'}
```

**ì›ì¸**:
- ë©”ëª¨ë¦¬ ë¶€ì¡± (RAM/VRAM)
- ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì´ˆê³¼
- ì„¸ê·¸ë©˜í…Œì´ì…˜ í´íŠ¸ (ë©”ëª¨ë¦¬ ì ‘ê·¼ ì˜¤ë¥˜)

**ë°œìƒ ìœ„ì¹˜**: Cross Reference Agent (ì±… ìƒì„± í›„ë°˜ë¶€)

**í•´ê²° ë°©ë²•**:
1. ë” ì‘ì€ ì–‘ìí™” ëª¨ë¸ ì‚¬ìš© (Q4 â†’ Q3)
2. ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì¤„ì´ê¸° (8192 â†’ 4096)
3. ì±•í„° ìˆ˜ ì¤„ì´ê¸° (3 â†’ 1)
4. ë°˜ë³µ íšŸìˆ˜ ì¤„ì´ê¸° (10 â†’ 2)

---

#### 2. No Models Loaded
```
Error code: 400 - {'error': {'message': "No models loaded. Please load a model..."}}
```

**ì›ì¸**:
- LM Studioì—ì„œ ëª¨ë¸ì´ ì–¸ë¡œë“œë¨
- ì´ì „ í¬ë˜ì‹œ í›„ ëª¨ë¸ ì¬ë¡œë“œ ì•ˆ ë¨
- LM Studio ì„œë²„ê°€ ì¤‘ì§€ë¨

**í•´ê²° ë°©ë²•**:
1. LM Studio ì•±ì—ì„œ ëª¨ë¸ ì¬ë¡œë“œ
2. Local Server ì¬ì‹œì‘
3. ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤í–‰

---

## âœ… LM Studio ì˜¬ë°”ë¥¸ ì„¤ì • ë°©ë²•

### 1ë‹¨ê³„: ëª¨ë¸ ì„ íƒ ë° ë¡œë“œ

**ê¶Œì¥ ëª¨ë¸**:
- **Qwen2.5-7B-Instruct** (Q4_K_M ì–‘ìí™”)
- **ìµœì†Œ ìš”êµ¬ì‚¬í•­**: 8GB RAM
- **ê¶Œì¥ ì‚¬ì–‘**: 16GB RAM, GPU ì§€ì›

**ë¡œë“œ ë°©ë²•**:
```
1. LM Studio ì•± ì‹¤í–‰
2. Models íƒ­ í´ë¦­
3. "Search for models" ê²€ìƒ‰ì°½ì— "qwen" ì…ë ¥
4. Qwen2.5-7B-Instruct ì°¾ê¸°
5. Q4_K_M ë²„ì „ ì„ íƒ (ê· í˜•ì¡íŒ ì„±ëŠ¥/ë©”ëª¨ë¦¬)
6. Download í´ë¦­ (ì²« ì‹¤í–‰ì‹œ)
7. Load Model í´ë¦­
8. ë¡œë”© ì™„ë£Œ ëŒ€ê¸° (ì§„í–‰ë¥  í‘œì‹œ)
```

---

### 2ë‹¨ê³„: Server ì„¤ì •

**ì„¤ì • í•­ëª©**:

1. **Context Length**:
   - **ê¶Œì¥**: 4096 (ì•ˆì •ì )
   - **ìµœëŒ€**: 8192 (ê³ ì„±ëŠ¥ ì‹œìŠ¤í…œ)
   - **ìµœì†Œ**: 2048 (ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ)

2. **GPU Offload**:
   - **GPU ìˆìŒ**: "Auto" ë˜ëŠ” ì „ì²´ ë ˆì´ì–´
   - **GPU ì—†ìŒ**: "None" (CPUë§Œ ì‚¬ìš©)

3. **Temperature**:
   - ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ ì„¤ì •í•˜ë¯€ë¡œ ê¸°ë³¸ê°’ ìœ ì§€

4. **Port**:
   - ê¸°ë³¸ê°’ 1234 ìœ ì§€

**ì„œë²„ ì‹œì‘**:
```
1. Local Server íƒ­ í´ë¦­
2. ìœ„ ì„¤ì • í™•ì¸
3. "Start Server" í´ë¦­
4. ìƒíƒœ í™•ì¸: "Server running on port 1234" í‘œì‹œë˜ì–´ì•¼ í•¨
5. ëª¨ë¸ì´ ë¡œë“œëœ ìƒíƒœë¡œ ìœ ì§€ë˜ëŠ”ì§€ í™•ì¸
```

---

### 3ë‹¨ê³„: ì—°ê²° í…ŒìŠ¤íŠ¸

**í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰**:
```bash
cd /Users/boon/Dropbox/02_works/94_agent
python main.py --test-connection
```

**ì˜ˆìƒ ì¶œë ¥** (ì„±ê³µ):
```
Testing connection to LM Studio at http://localhost:1234/v1...
âœ“ Successfully connected to LM Studio
  Model: qwen
```

**ì˜ˆìƒ ì¶œë ¥** (ì‹¤íŒ¨):
```
âœ— Failed to connect to LM Studio

Troubleshooting:
1. Make sure LM Studio is running
2. Check that the local server is started (port 1234)
3. Verify the model is loaded
```

---

## ğŸ›  ë¬¸ì œë³„ í•´ê²° ë°©ë²•

### ë¬¸ì œ 1: ëª¨ë¸ì´ ìê¾¸ í¬ë˜ì‹œë¨

**ì¦ìƒ**:
- ì±… ìƒì„± ì¤‘ê°„ì— "Exit code: 11" ì˜¤ë¥˜
- Cross Reference Agentì—ì„œ ì£¼ë¡œ ë°œìƒ

**ì›ì¸**:
- ëˆ„ì  ì»¨í…ìŠ¤íŠ¸ê°€ ëª¨ë¸ í•œê³„ ì´ˆê³¼
- ë©”ëª¨ë¦¬ ë¶€ì¡±

**í•´ê²°ì±…**:

#### A. ë” ê°€ë²¼ìš´ ì„¤ì • ì‚¬ìš©
```bash
# 1ì±•í„°ë§Œ ìƒì„±
python main.py --mode book --book-type history --topic "ì• í”Œì˜ ì—­ì‚¬" --chapters 1 --max-iterations 1

# ë°˜ë³µ ì¤„ì´ê¸°
python main.py --mode book --book-type history --topic "ì• í”Œì˜ ì—­ì‚¬" --chapters 3 --max-iterations 2
```

#### B. ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©
- Qwen2.5-7B Q4_K_M â†’ Q3_K_M
- ë˜ëŠ” Qwen2.5-3B ëª¨ë¸ ì‚¬ìš©

#### C. Context Length ì¤„ì´ê¸°
LM Studio Server ì„¤ì •:
- 8192 â†’ 4096
- ë˜ëŠ” 4096 â†’ 2048

#### D. LM Studio ì¬ì‹œì‘
```
1. LM Studioì—ì„œ "Stop Server" í´ë¦­
2. ëª¨ë¸ Unload
3. LM Studio ì•± ì™„ì „ ì¢…ë£Œ
4. ì•± ì¬ì‹œì‘
5. ëª¨ë¸ ì¬ë¡œë“œ
6. ì„œë²„ ì¬ì‹œì‘
```

---

### ë¬¸ì œ 2: ì—°ê²° í…ŒìŠ¤íŠ¸ëŠ” ì„±ê³µí•˜ëŠ”ë° ì‹¤í–‰ ì‹œ ì‹¤íŒ¨

**ì¦ìƒ**:
- `python main.py --test-connection` ì„±ê³µ
- ì‹¤ì œ ìƒì„± ì‹œì‘í•˜ë©´ "No models loaded" ì˜¤ë¥˜

**ì›ì¸**:
- í…ŒìŠ¤íŠ¸ í›„ ëª¨ë¸ì´ ìë™ ì–¸ë¡œë“œë¨
- LM Studio ì„¤ì • ë¬¸ì œ

**í•´ê²°ì±…**:

#### A. ëª¨ë¸ ìƒíƒœ ìœ ì§€ í™•ì¸
```
1. LM Studio ì•± ì—´ê¸°
2. Models íƒ­ì—ì„œ ëª¨ë¸ ìƒíƒœ í™•ì¸
3. "Loaded" ìƒíƒœì—¬ì•¼ í•¨
4. Local Server íƒ­ì—ì„œ "Running" í™•ì¸
5. ì„œë²„ë¥¼ ì¤‘ì§€í•˜ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ìœ ì§€
```

#### B. Auto-unload ì„¤ì • ë¹„í™œì„±í™”
LM Studio ì„¤ì • (Settings):
- "Auto-unload models" ì˜µì…˜ ë„ê¸° (ìˆë‹¤ë©´)

#### C. ì—°ê²° í…ŒìŠ¤íŠ¸ ì§í›„ ì¦‰ì‹œ ì‹¤í–‰
```bash
# í…ŒìŠ¤íŠ¸ì™€ ì‹¤í–‰ì„ ì—°ì†ìœ¼ë¡œ
python main.py --test-connection && python main.py --mode simple --topic "í…ŒìŠ¤íŠ¸"
```

---

### ë¬¸ì œ 3: ìƒì„± ì†ë„ê°€ ë„ˆë¬´ ëŠë¦¼

**ì¦ìƒ**:
- í† í° ìƒì„±ì´ ì´ˆë‹¹ 1-2ê°œ
- ì±•í„° í•˜ë‚˜ ìƒì„±ì— 30ë¶„ ì´ìƒ ì†Œìš”

**ì›ì¸**:
- CPUë§Œ ì‚¬ìš© (GPU ë¯¸ì‚¬ìš©)
- ëª¨ë¸ í¬ê¸°ê°€ ì‹œìŠ¤í…œì— ë¹„í•´ í¼

**í•´ê²°ì±…**:

#### A. GPU ê°€ì† í™•ì¸
LM Studio Server ì„¤ì •:
- GPU Offload: "Auto" ë˜ëŠ” ìµœëŒ€ê°’

ì‹œìŠ¤í…œì— GPUê°€ ìˆëŠ”ì§€ í™•ì¸:
- Mac: M1/M2/M3 ì¹© (Metal ê°€ì†)
- Windows/Linux: NVIDIA GPU (CUDA)

#### B. ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©
- Qwen2.5-7B â†’ Qwen2.5-3B
- Q4_K_M â†’ Q4_K_S (ë” ë¹ ë¦„, í’ˆì§ˆ ì•½ê°„ ë‚®ìŒ)

#### C. Batch Size ì¡°ì •
LM Studio Advanced ì„¤ì •:
- Batch Size ì¦ê°€ (ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•˜ë©´)

---

### ë¬¸ì œ 4: DuckDuckGo Search ê²½ê³ 

**ì¦ìƒ**:
```
Warning: duckduckgo-search not installed. Install with: pip install duckduckgo-search
```

**í•´ê²°ì±…**:
```bash
pip install duckduckgo-search
```

ì„¤ì¹˜ í›„ í™•ì¸:
```bash
python -c "import duckduckgo_search; print('âœ“ Installed')"
```

---

## ğŸ“‹ ê¶Œì¥ ì›Œí¬í”Œë¡œìš°

### ì•ˆì •ì ì¸ ì±… ìƒì„± í”„ë¡œì„¸ìŠ¤

#### 1. LM Studio ì¤€ë¹„
```
1. LM Studio ì‹¤í–‰
2. Qwen2.5-7B-Instruct (Q4_K_M) ë¡œë“œ
3. Server ì„¤ì •:
   - Context Length: 4096
   - GPU: Auto
4. Start Server
5. ìƒíƒœ í™•ì¸: "Running"
```

#### 2. ì—°ê²° í…ŒìŠ¤íŠ¸
```bash
python main.py --test-connection
```

#### 3. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
# ì§§ì€ ê¸€ë¶€í„° í…ŒìŠ¤íŠ¸
python main.py --mode simple --topic "ì¸ê³µì§€ëŠ¥ì˜ ì—­ì‚¬" --max-iterations 1
```

#### 4. ì±… ìƒì„± (ë‹¨ê³„ì )
```bash
# 1ì±•í„°ë§Œ ë¨¼ì €
python main.py --mode book --book-type history --topic "ì• í”Œì˜ ì—­ì‚¬" --chapters 1 --max-iterations 2

# ì„±ê³µí•˜ë©´ 3ì±•í„°ë¡œ
python main.py --mode book --book-type history --topic "ì• í”Œì˜ ì—­ì‚¬" --chapters 3 --max-iterations 2
```

---

## ğŸ¯ ìµœì  ì„¤ì • ì¡°í•©

### ê³ ì„±ëŠ¥ ì‹œìŠ¤í…œ (16GB+ RAM, GPU)
```bash
# LM Studio ì„¤ì •
- Model: Qwen2.5-7B-Instruct (Q4_K_M)
- Context: 8192
- GPU: Full offload

# ì‹¤í–‰ ëª…ë ¹
python main.py --mode book --book-type history --topic "ì£¼ì œ" --chapters 5 --max-iterations 3
```

### ì¤‘ê°„ ì‹œìŠ¤í…œ (8-16GB RAM)
```bash
# LM Studio ì„¤ì •
- Model: Qwen2.5-7B-Instruct (Q4_K_M)
- Context: 4096
- GPU: Auto

# ì‹¤í–‰ ëª…ë ¹
python main.py --mode book --book-type history --topic "ì£¼ì œ" --chapters 3 --max-iterations 2
```

### ì €ì‚¬ì–‘ ì‹œìŠ¤í…œ (8GB RAM)
```bash
# LM Studio ì„¤ì •
- Model: Qwen2.5-3B-Instruct (Q4_K_M)
- Context: 2048
- GPU: Auto

# ì‹¤í–‰ ëª…ë ¹
python main.py --mode simple --topic "ì£¼ì œ" --max-iterations 1
```

---

## ğŸ” ë””ë²„ê¹… íŒ

### ë¡œê·¸ í™•ì¸
ì—ëŸ¬ ë°œìƒ ì‹œ ì „ì²´ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì €ì¥:
```bash
python main.py --mode book --book-type history --topic "ì£¼ì œ" --chapters 3 2>&1 | tee error.log
```

### ìƒíƒœ ì €ì¥ ìœ„ì¹˜
ì„¸ì…˜ ë°ì´í„° í™•ì¸:
```bash
# Checkpoint DB
ls -lh data/checkpoints.sqlite

# ìƒì„±ëœ ì±…
ls -R output/books/
```

### Thread IDë¡œ ì¬ê°œ
í¬ë˜ì‹œ í›„ ì¬ê°œ:
```bash
# ì—ëŸ¬ ë©”ì‹œì§€ì—ì„œ Session ID í™•ì¸
# ì˜ˆ: Session ID: e8d52f69-c279-4579-a6bf-0cdb75ebb89b

python main.py --mode book --thread-id e8d52f69-c279-4579-a6bf-0cdb75ebb89b
```

---

## ğŸ“ ì¶”ê°€ ë„ì›€ë§

### LM Studio ê³µì‹ ë¬¸ì„œ
- https://lmstudio.ai/docs

### ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
- Hugging Face: https://huggingface.co/Qwen

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸
```bash
# ë©”ëª¨ë¦¬ í™•ì¸ (Mac)
sysctl hw.memsize

# ë©”ëª¨ë¦¬ í™•ì¸ (Linux)
free -h

# Python í™˜ê²½
python --version
pip list | grep -E "(langgraph|openai|duckduckgo)"
```

---

**ì‘ì„±ì¼**: 2025-12-28
**ë²„ì „**: 1.0
**ì‹œìŠ¤í…œ**: Writer-Editor Multi-Agent Book System
