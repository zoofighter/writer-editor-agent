# í”„ë¡œì íŠ¸ ê°œì„  ì œì•ˆì„œ

## ğŸ“‹ ëª©ì°¨

1. [í˜„ì¬ ì‹œìŠ¤í…œ í‰ê°€](#í˜„ì¬-ì‹œìŠ¤í…œ-í‰ê°€)
2. [ìš°ì„ ìˆœìœ„ë³„ ê°œì„  ì œì•ˆ](#ìš°ì„ ìˆœìœ„ë³„-ê°œì„ -ì œì•ˆ)
3. [ê¸°ìˆ ì  ê°œì„ ](#ê¸°ìˆ ì -ê°œì„ )
4. [ê¸°ëŠ¥ í™•ì¥](#ê¸°ëŠ¥-í™•ì¥)
5. [ì‚¬ìš©ì ê²½í—˜ ê°œì„ ](#ì‚¬ìš©ì-ê²½í—˜-ê°œì„ )
6. [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)
7. [í’ˆì§ˆ ë³´ì¦](#í’ˆì§ˆ-ë³´ì¦)
8. [ë°°í¬ ë° ìš´ì˜](#ë°°í¬-ë°-ìš´ì˜)
9. [êµ¬í˜„ ë¡œë“œë§µ](#êµ¬í˜„-ë¡œë“œë§µ)

---

## í˜„ì¬ ì‹œìŠ¤í…œ í‰ê°€

### âœ… ì˜ êµ¬í˜„ëœ ë¶€ë¶„

#### 1. ì•„í‚¤í…ì²˜
- **LangGraph ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°**: ëª…í™•í•œ ì—ì´ì „íŠ¸ ë¶„ë¦¬ì™€ ìƒíƒœ ê´€ë¦¬
- **TypedDict ìƒíƒœ ìŠ¤í‚¤ë§ˆ**: íƒ€ì… ì•ˆì „ì„± í™•ë³´
- **Reducer íŒ¨í„´**: íš¨ìœ¨ì ì¸ ìƒíƒœ ëˆ„ì 
- **SQLite Checkpointing**: ì„¸ì…˜ ì˜ì†í™” ë° ì¬ê°œ ê¸°ëŠ¥

#### 2. ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
- **6ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸**: Business Analyst, Book Coordinator, Content Strategist, Writer, Editor, Web Search
- **5ê°œ ë³´ì¡° ì—ì´ì „íŠ¸**: Fact Check, Math Formula, Diagram, Bibliography, Cross Reference
- **ì—ì´ì „íŠ¸ë³„ Temperature ì„¤ì •**: ì—­í• ì— ë§ëŠ” ì°½ì˜ì„±/ì •í™•ì„± ì¡°ì •

#### 3. í…œí”Œë¦¿ ì‹œìŠ¤í…œ
- **7ê°€ì§€ ë¬¸ì„œ íƒ€ì…** ì§€ì›
- **êµ¬ì¡°í™”ëœ ëª©ì°¨ ìƒì„±**
- **ì„¹ì…˜ë³„ ë¦¬ì„œì¹˜ ì¿¼ë¦¬**

#### 4. ë‚´ë³´ë‚´ê¸°
- **Markdown ì¶œë ¥**
- **PDF ìƒì„± ì§€ì›** (pandoc)
- **ì±•í„°ë³„/ì™„ì „í•œ ì±… ì¡°ë¦½**

### âš ï¸ ê°œì„  í•„ìš” ë¶€ë¶„

#### 1. ì•ˆì •ì„± ë¬¸ì œ
- **ëª¨ë¸ í¬ë˜ì‹œ**: Exit code 11 (ë©”ëª¨ë¦¬ ë¶€ì¡±)
- **ëª¨ë¸ ìë™ ì–¸ë¡œë“œ**: ì—°ê²° í…ŒìŠ¤íŠ¸ í›„ ì‹¤í–‰ ì‹œ ì‹¤íŒ¨
- **ì»¨í…ìŠ¤íŠ¸ ëˆ„ì **: Cross Reference ë‹¨ê³„ì—ì„œ í•œê³„ ë„ë‹¬

#### 2. ê¸°ëŠ¥ ì œí•œ
- **ì–¸ì–´ ì„¤ì • ëˆ„ë½**: í•œê¸€ ìš”ì²­ì—ë„ ì˜ì–´ ì¶œë ¥
- **í”¼ë“œë°± ë£¨í”„ ë¯¸ì‘ë™**: Writerê°€ Editor í”¼ë“œë°± ë¯¸ë°˜ì˜
- **ì›¹ ê²€ìƒ‰ ì„ íƒì§€ ì œí•œ**: DuckDuckGoë§Œ (Tavily, Serper ë¯¸êµ¬í˜„)

#### 3. ì‚¬ìš©ì ê²½í—˜
- **ì—ëŸ¬ ë©”ì‹œì§€ ë¶ˆì¹œì ˆ**: ê¸°ìˆ ì  ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ë§Œ
- **ì§„í–‰ ìƒí™© ì‹œê°í™” ë¶€ì¡±**: ì–´ëŠ ë‹¨ê³„ì¸ì§€ ë¶ˆëª…í™•
- **ì¤‘ë‹¨ ì‹œ ë³µêµ¬ ì–´ë ¤ì›€**: Thread ID ìˆ˜ë™ ì…ë ¥

#### 4. ì„±ëŠ¥
- **ë°˜ë³µ ìƒì„±**: ë™ì¼ ì´ˆì•ˆ 5-6íšŒ ë°˜ë³µ
- **ë¶ˆí•„ìš”í•œ ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬**: ëª¨ë“  ì—ì´ì „íŠ¸ì— ì „ì²´ íˆìŠ¤í† ë¦¬
- **ë³‘ë ¬ ì²˜ë¦¬ ë¯¸í™œìš©**: ë…ë¦½ì ì¸ ì‘ì—…ë„ ìˆœì°¨ ì‹¤í–‰

---

## ìš°ì„ ìˆœìœ„ë³„ ê°œì„  ì œì•ˆ

### ğŸ”´ ê¸´ê¸‰ (1-2ì£¼)

#### 1. ì•ˆì •ì„± í™•ë³´
**ë¬¸ì œ**: ëª¨ë¸ í¬ë˜ì‹œë¡œ ì±… ìƒì„± ì‹¤íŒ¨
**í•´ê²°**:
- [ ] ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ê°œì„ 
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
- [ ] ì¬ì‹œë„ ë¡œì§ ì¶”ê°€
- [ ] ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§

#### 2. ì–¸ì–´ ì„¤ì • ìˆ˜ì •
**ë¬¸ì œ**: í•œê¸€ ì£¼ì œì—ë„ ì˜ì–´ë¡œ ì‘ì„±
**í•´ê²°**:
- [ ] ì–¸ì–´ ê°ì§€ ë¡œì§
- [ ] í”„ë¡¬í”„íŠ¸ì— ì–¸ì–´ ëª…ì‹œ
- [ ] ë‹¤êµ­ì–´ í…œí”Œë¦¿

#### 3. í”¼ë“œë°± ë£¨í”„ ìˆ˜ì •
**ë¬¸ì œ**: Writerê°€ Editor í”¼ë“œë°± ë¯¸ë°˜ì˜
**í•´ê²°**:
- [ ] Writer revise ë¡œì§ ê°œì„ 
- [ ] í”¼ë“œë°± íŒŒì‹± ê°•í™”
- [ ] ë°˜ë³µ ì¡°ê±´ ëª…í™•í™”

---

### ğŸŸ¡ ì¤‘ìš” (2-4ì£¼)

#### 4. ì›¹ ê²€ìƒ‰ í™•ì¥
**í˜„ì¬**: DuckDuckGoë§Œ ì§€ì›
**ê°œì„ **:
- [ ] Tavily API í†µí•©
- [ ] Serper API í†µí•©
- [ ] ê²€ìƒ‰ ê²°ê³¼ ìºì‹±
- [ ] ì¶œì²˜ ê²€ì¦ ê°•í™”

#### 5. ì‚¬ìš©ì ê²½í—˜ ê°œì„ 
**ê°œì„  ì‚¬í•­**:
- [ ] ì§„í–‰ ìƒí™© ë°”
- [ ] ì¹œì ˆí•œ ì—ëŸ¬ ë©”ì‹œì§€
- [ ] ìë™ ì„¸ì…˜ ì¬ê°œ
- [ ] ì¤‘ê°„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°

#### 6. ì„±ëŠ¥ ìµœì í™”
**ê°œì„  ì‚¬í•­**:
- [ ] ë³‘ë ¬ ì—ì´ì „íŠ¸ ì‹¤í–‰
- [ ] ì»¨í…ìŠ¤íŠ¸ ì••ì¶•
- [ ] ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
- [ ] ìºì‹± ì „ëµ

---

### ğŸŸ¢ ì¼ë°˜ (4-8ì£¼)

#### 7. ìƒˆë¡œìš´ ê¸°ëŠ¥
**í™•ì¥ ê¸°ëŠ¥**:
- [ ] ì´ë¯¸ì§€ ìƒì„± í†µí•©
- [ ] ìŒì„± ì¶œë ¥ (TTS)
- [ ] ë‹¤êµ­ì–´ ë²ˆì—­
- [ ] í˜‘ì—… ëª¨ë“œ

#### 8. í’ˆì§ˆ ë³´ì¦
**QA ê°œì„ **:
- [ ] ìœ ë‹› í…ŒìŠ¤íŠ¸ í™•ëŒ€
- [ ] í†µí•© í…ŒìŠ¤íŠ¸
- [ ] E2E í…ŒìŠ¤íŠ¸
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

#### 9. ë°°í¬ ê°œì„ 
**DevOps**:
- [ ] Docker ì»¨í…Œì´ë„ˆí™”
- [ ] CI/CD íŒŒì´í”„ë¼ì¸
- [ ] í´ë¼ìš°ë“œ ë°°í¬
- [ ] ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

---

## ê¸°ìˆ ì  ê°œì„ 

### 1. ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ê°œì„ 

#### ë¬¸ì œì 
í˜„ì¬ ëª¨ë“  ì—ì´ì „íŠ¸ì— ì „ì²´ `conversation_history` ì „ë‹¬:
```python
# í˜„ì¬ (ë¬¸ì œ)
state = {
    "conversation_history": [...],  # ëª¨ë“  ëŒ€í™”
    "iterations": [...],            # ëª¨ë“  ë°˜ë³µ
    ...
}
```

#### í•´ê²° ë°©ì•ˆ A: ì»¨í…ìŠ¤íŠ¸ ì••ì¶•

**íŒŒì¼**: `src/utils/context_manager.py` (ì‹ ê·œ)

```python
from typing import List, Dict, Any

class ContextManager:
    """ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ë° ì••ì¶•"""

    @staticmethod
    def compress_conversation_history(
        history: List[Dict],
        max_items: int = 5,
        summary_threshold: int = 10
    ) -> List[Dict]:
        """
        ëŒ€í™” íˆìŠ¤í† ë¦¬ ì••ì¶•.

        ì „ëµ:
        1. ìµœê·¼ Nê°œëŠ” ì „ì²´ ìœ ì§€
        2. ì˜¤ë˜ëœ ê²ƒë“¤ì€ ìš”ì•½
        """
        if len(history) <= max_items:
            return history

        # ì˜¤ë˜ëœ ë©”ì‹œì§€ë“¤ ìš”ì•½
        old_messages = history[:-max_items]
        recent_messages = history[-max_items:]

        summary = {
            "role": "system",
            "content": f"[Summary of {len(old_messages)} previous messages]"
        }

        return [summary] + recent_messages

    @staticmethod
    def compress_iterations(
        iterations: List[Dict],
        keep_last_n: int = 2
    ) -> List[Dict]:
        """
        ë°˜ë³µ ì´ë ¥ ì••ì¶•.

        ìµœê·¼ Nê°œë§Œ ìœ ì§€, ë‚˜ë¨¸ì§€ëŠ” ìš”ì•½
        """
        if len(iterations) <= keep_last_n:
            return iterations

        old_iterations = iterations[:-keep_last_n]
        recent_iterations = iterations[-keep_last_n:]

        summary = {
            "iteration": "summary",
            "content": f"Previous {len(old_iterations)} iterations",
            "final_draft_length": old_iterations[-1].get("draft_length", 0)
        }

        return [summary] + recent_iterations

    @staticmethod
    def get_relevant_context_for_agent(
        state: Dict[str, Any],
        agent_name: str
    ) -> Dict[str, Any]:
        """
        ì—ì´ì „íŠ¸ë³„ í•„ìš”í•œ ì»¨í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ.

        ì˜ˆ:
        - Writer: topic, outline, research_data, last_feedback
        - Editor: current_draft, outline
        - Cross Reference: current_draft, terminology_glossary (conversation_history ì œì™¸)
        """
        common = {
            "topic": state.get("topic"),
        }

        agent_specific = {
            "writer": {
                **common,
                "current_outline": state.get("current_outline"),
                "research_by_section": state.get("research_by_section"),
                "current_feedback": state.get("current_feedback"),
                "iteration_count": state.get("iteration_count"),
            },
            "editor": {
                **common,
                "current_draft": state.get("current_draft"),
                "current_outline": state.get("current_outline"),
                "iteration_count": state.get("iteration_count"),
            },
            "cross_reference": {
                "current_draft": state.get("current_draft"),
                "terminology_glossary": state.get("terminology_glossary"),
                "completed_chapters": state.get("completed_chapters"),
                # conversation_history ì œì™¸!
            },
            "fact_check": {
                "current_draft": state.get("current_draft"),
                "research_data": state.get("research_data"),
            }
        }

        return agent_specific.get(agent_name, common)
```

**ì ìš©**:
```python
# src/agents/cross_reference_agent.py

from src.utils.context_manager import ContextManager

def cross_reference_node(state: WorkflowState) -> Dict[str, Any]:
    """Cross Reference Agent ë…¸ë“œ (ê°œì„ )"""

    # í•„ìš”í•œ ì»¨í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
    context = ContextManager.get_relevant_context_for_agent(state, "cross_reference")

    agent = CrossReferenceAgent(client)

    # ì „ì²´ state ëŒ€ì‹  í•„ìš”í•œ ê²ƒë§Œ
    identified_refs = agent.identify_cross_references(
        current_draft=context["current_draft"],
        terminology_glossary=context["terminology_glossary"],
        # conversation_historyëŠ” ì „ë‹¬ ì•ˆ í•¨ -> ë©”ëª¨ë¦¬ ì ˆì•½
    )

    return {"cross_references": identified_refs}
```

#### í•´ê²° ë°©ì•ˆ B: ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ

**íŒŒì¼**: `src/llm/client.py`

```python
def generate_streaming(
    self,
    messages: List[Dict],
    temperature: float = None,
    max_tokens: int = None,
    callback: callable = None
) -> str:
    """
    ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ ì‘ë‹µ ìƒì„±.

    Args:
        messages: ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        temperature: ì˜¨ë„
        max_tokens: ìµœëŒ€ í† í°
        callback: ì²­í¬ë³„ ì½œë°± (ì§„í–‰ ìƒí™© í‘œì‹œìš©)

    Returns:
        ì „ì²´ ì‘ë‹µ ë¬¸ìì—´
    """
    try:
        response = self.client.chat.completions.create(
            model=self.model_name,
            messages=messages,
            temperature=temperature or self.temperature,
            max_tokens=max_tokens or self.max_tokens,
            stream=True  # ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
        )

        full_response = ""
        for chunk in response:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                full_response += content

                # ì½œë°± í˜¸ì¶œ (UI ì—…ë°ì´íŠ¸)
                if callback:
                    callback(content)

        return full_response

    except Exception as e:
        raise Exception(f"Streaming generation failed: {e}")
```

**ì‚¬ìš© ì˜ˆ**:
```python
# src/agents/writer.py

def create_draft(self, topic: str, ...):
    """ì´ˆì•ˆ ì‘ì„± (ìŠ¤íŠ¸ë¦¬ë°)"""

    def on_chunk(text: str):
        print(text, end="", flush=True)  # ì‹¤ì‹œê°„ ì¶œë ¥

    response = self.llm_client.generate_streaming(
        messages=messages,
        callback=on_chunk
    )

    return response
```

---

### 2. ì–¸ì–´ ì„¤ì • ê°œì„ 

#### íŒŒì¼: `src/utils/language_detector.py` (ì‹ ê·œ)

```python
import re
from typing import Literal

Language = Literal["ko", "en", "ja", "zh"]

class LanguageDetector:
    """ì–¸ì–´ ê°ì§€"""

    @staticmethod
    def detect(text: str) -> Language:
        """
        í…ìŠ¤íŠ¸ì—ì„œ ì–¸ì–´ ê°ì§€.

        ìš°ì„ ìˆœìœ„:
        1. í•œê¸€ (ê°€-í£)
        2. ì¼ë³¸ì–´ (ã-ã‚“, ã‚¡-ãƒ¶, ä¸€-é¾¯)
        3. ì¤‘êµ­ì–´ (ç®€ä½“/ç¹ä½“)
        4. ê¸°ë³¸: ì˜ì–´
        """
        # í•œê¸€
        if re.search(r'[ê°€-í£]', text):
            return "ko"

        # ì¼ë³¸ì–´ (íˆë¼ê°€ë‚˜, ì¹´íƒ€ì¹´ë‚˜, í•œì)
        if re.search(r'[ã-ã‚“ã‚¡-ãƒ¶]', text):
            return "ja"

        # ì¤‘êµ­ì–´ (í•œì)
        if re.search(r'[\u4e00-\u9fff]', text):
            return "zh"

        # ê¸°ë³¸: ì˜ì–´
        return "en"

    @staticmethod
    def get_language_instruction(lang: Language) -> str:
        """ì–¸ì–´ë³„ í”„ë¡¬í”„íŠ¸ ì§€ì‹œì‚¬í•­"""
        instructions = {
            "ko": "IMPORTANT: Write ALL content in Korean (í•œê¸€). Do not use English.",
            "en": "Write in English.",
            "ja": "IMPORTANT: Write ALL content in Japanese (æ—¥æœ¬èª).",
            "zh": "IMPORTANT: Write ALL content in Chinese (ä¸­æ–‡)."
        }
        return instructions.get(lang, instructions["en"])

    @staticmethod
    def get_language_name(lang: Language) -> str:
        """ì–¸ì–´ ì´ë¦„"""
        names = {
            "ko": "Korean (í•œêµ­ì–´)",
            "en": "English",
            "ja": "Japanese (æ—¥æœ¬èª)",
            "zh": "Chinese (ä¸­æ–‡)"
        }
        return names.get(lang, "English")
```

#### ì ìš©: Writer Agent

**íŒŒì¼**: `src/agents/writer.py`

```python
from src.utils.language_detector import LanguageDetector

class WriterAgent:
    """Writer Agent (ì–¸ì–´ ê°ì§€ ì¶”ê°€)"""

    def create_initial_draft(
        self,
        topic: str,
        user_intent: Optional[Dict] = None,
        outline: Optional[Dict] = None,
        research_data: Optional[Dict] = None
    ) -> str:
        """ì´ˆì•ˆ ì‘ì„± (ì–¸ì–´ ê°ì§€)"""

        # ì–¸ì–´ ê°ì§€
        detected_lang = LanguageDetector.detect(topic)
        lang_instruction = LanguageDetector.get_language_instruction(detected_lang)
        lang_name = LanguageDetector.get_language_name(detected_lang)

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì–¸ì–´ ì§€ì‹œ ì¶”ê°€
        system_prompt = f"""{self.SYSTEM_PROMPT}

{lang_instruction}

The topic is in {lang_name}, so your output MUST be in {lang_name}.
"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"Topic: {topic}\n\nCreate a draft."}
        ]

        return self.llm_client.generate(messages)
```

---

### 3. ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”

#### íŒŒì¼: `src/llm/client.py` (ê°œì„ )

```python
import time
from typing import Optional, List, Dict

class LMStudioError(Exception):
    """LM Studio ê´€ë ¨ ì—ëŸ¬ ê¸°ë³¸ í´ë˜ìŠ¤"""
    pass

class ModelCrashError(LMStudioError):
    """ëª¨ë¸ í¬ë˜ì‹œ ì—ëŸ¬ (Exit code 11)"""
    pass

class ModelNotLoadedError(LMStudioError):
    """ëª¨ë¸ ë¯¸ë¡œë“œ ì—ëŸ¬"""
    pass

class ContextLengthExceededError(LMStudioError):
    """ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì´ˆê³¼"""
    pass


class LMStudioClient:
    """LM Studio Client (ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”)"""

    def generate(
        self,
        messages: List[Dict],
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        max_retries: int = 3,
        retry_delay: float = 2.0
    ) -> str:
        """
        LLM ì‘ë‹µ ìƒì„± (ì¬ì‹œë„ ë¡œì§ í¬í•¨).

        Args:
            messages: ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            temperature: ì˜¨ë„
            max_tokens: ìµœëŒ€ í† í°
            max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
            retry_delay: ì¬ì‹œë„ ê°„ê²© (ì´ˆ)

        Returns:
            ìƒì„±ëœ í…ìŠ¤íŠ¸

        Raises:
            ModelCrashError: ëª¨ë¸ í¬ë˜ì‹œ
            ModelNotLoadedError: ëª¨ë¸ ë¯¸ë¡œë“œ
            ContextLengthExceededError: ì»¨í…ìŠ¤íŠ¸ ì´ˆê³¼
            LMStudioError: ê¸°íƒ€ LM Studio ì—ëŸ¬
        """
        for attempt in range(max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=messages,
                    temperature=temperature or self.temperature,
                    max_tokens=max_tokens or self.max_tokens
                )

                return response.choices[0].message.content

            except Exception as e:
                error_msg = str(e)

                # ì—ëŸ¬ ë¶„ë¥˜
                if "Exit code: 11" in error_msg or "crashed" in error_msg.lower():
                    raise ModelCrashError(
                        "LM Studio model crashed (Exit code 11).\n\n"
                        "Possible causes:\n"
                        "1. Out of memory (RAM/VRAM)\n"
                        "2. Context length exceeded\n"
                        "3. Model internal error\n\n"
                        "Solutions:\n"
                        "- Restart LM Studio\n"
                        "- Reduce context length (8192 â†’ 4096)\n"
                        "- Use smaller model or quantization\n"
                        "- Reduce --chapters or --max-iterations"
                    ) from e

                if "No models loaded" in error_msg:
                    # ì¬ì‹œë„ ê°€ëŠ¥
                    if attempt < max_retries - 1:
                        print(f"âš ï¸  Model not loaded. Retrying {attempt+1}/{max_retries}...")
                        time.sleep(retry_delay * (2 ** attempt))  # ì§€ìˆ˜ ë°±ì˜¤í”„
                        continue

                    raise ModelNotLoadedError(
                        "No models loaded in LM Studio.\n\n"
                        "Please:\n"
                        "1. Open LM Studio application\n"
                        "2. Load a model (Models tab)\n"
                        "3. Start local server (Local Server tab)\n"
                        "4. Verify: python main.py --test-connection"
                    ) from e

                if "context length" in error_msg.lower():
                    raise ContextLengthExceededError(
                        "Context length exceeded.\n\n"
                        "Solutions:\n"
                        "- Reduce context in LM Studio settings\n"
                        "- Reduce iteration count\n"
                        "- Enable context compression"
                    ) from e

                # ê¸°íƒ€ ì—ëŸ¬
                if attempt < max_retries - 1:
                    print(f"âš ï¸  API call failed. Retrying {attempt+1}/{max_retries}...")
                    time.sleep(retry_delay)
                    continue

                raise LMStudioError(f"LM Studio API call failed: {e}") from e

        raise LMStudioError(f"Failed after {max_retries} attempts")
```

#### ì ìš©: ì—ì´ì „íŠ¸ ë…¸ë“œ

```python
# src/agents/writer.py

def writer_node(state: WorkflowState) -> Dict[str, Any]:
    """Writer ë…¸ë“œ (ì—ëŸ¬ ì²˜ë¦¬)"""

    try:
        agent = WriterAgent(client)

        if state["iteration_count"] == 0:
            draft = agent.create_initial_draft(...)
        else:
            draft = agent.revise_draft(...)

        return {"current_draft": draft}

    except ModelCrashError as e:
        # ëª¨ë¸ í¬ë˜ì‹œ ì‹œ ìƒíƒœ ì €ì¥ í›„ ì¢…ë£Œ
        print(f"\nâŒ {e}")
        print("\nğŸ’¾ Session saved. Resume with:")
        print(f"   python main.py --thread-id {state.get('thread_id')}")

        # ìƒíƒœ ì €ì¥ì€ LangGraph checkpointerê°€ ìë™ ì²˜ë¦¬
        raise  # ì›Œí¬í”Œë¡œìš° ì¤‘ë‹¨

    except ContextLengthExceededError:
        # ì»¨í…ìŠ¤íŠ¸ ì´ˆê³¼ ì‹œ ì••ì¶• í›„ ì¬ì‹œë„
        print("âš ï¸  Context length exceeded. Compressing...")

        compressed_state = ContextManager.compress_state(state)

        agent = WriterAgent(client)
        draft = agent.create_initial_draft_minimal(compressed_state)

        return {"current_draft": draft}

    except ModelNotLoadedError as e:
        print(f"\nâŒ {e}")
        raise  # ì›Œí¬í”Œë¡œìš° ì¤‘ë‹¨
```

---

### 4. ì§„í–‰ ìƒí™© ì‹œê°í™”

#### íŒŒì¼: `src/ui/progress_tracker.py` (ì‹ ê·œ)

```python
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskID
from rich.console import Console
from typing import Optional

class ProgressTracker:
    """ì§„í–‰ ìƒí™© ì¶”ì  ë° í‘œì‹œ"""

    def __init__(self):
        self.console = Console()
        self.progress = Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            console=self.console
        )
        self.tasks = {}

    def start(self):
        """ì§„í–‰ ë°” ì‹œì‘"""
        self.progress.start()

    def stop(self):
        """ì§„í–‰ ë°” ì¢…ë£Œ"""
        self.progress.stop()

    def add_book_task(self, book_title: str, total_chapters: int) -> TaskID:
        """ì±… ìƒì„± ì‘ì—… ì¶”ê°€"""
        task_id = self.progress.add_task(
            f"ğŸ“š {book_title}",
            total=total_chapters
        )
        self.tasks["book"] = task_id
        return task_id

    def add_chapter_task(self, chapter_number: int) -> TaskID:
        """ì±•í„° ì‘ì—… ì¶”ê°€"""
        task_id = self.progress.add_task(
            f"  ğŸ“ Chapter {chapter_number}",
            total=10  # 10 ë‹¨ê³„ (ì—ì´ì „íŠ¸ ìˆ˜)
        )
        self.tasks[f"chapter_{chapter_number}"] = task_id
        return task_id

    def update_chapter(self, chapter_number: int, agent_name: str):
        """ì±•í„° ì§„í–‰ ì—…ë°ì´íŠ¸"""
        task_id = self.tasks.get(f"chapter_{chapter_number}")
        if task_id:
            self.progress.update(
                task_id,
                advance=1,
                description=f"  ğŸ“ Chapter {chapter_number} - {agent_name}"
            )

    def complete_chapter(self, chapter_number: int):
        """ì±•í„° ì™„ë£Œ"""
        # ì±•í„° ì‘ì—… ì™„ë£Œ
        chapter_task_id = self.tasks.get(f"chapter_{chapter_number}")
        if chapter_task_id:
            self.progress.update(chapter_task_id, completed=10)

        # ì±… ì „ì²´ ì§„í–‰ ì—…ë°ì´íŠ¸
        book_task_id = self.tasks.get("book")
        if book_task_id:
            self.progress.update(book_task_id, advance=1)
```

#### ì ìš©: CLI

**íŒŒì¼**: `src/ui/cli.py`

```python
from src.ui.progress_tracker import ProgressTracker

class CLI:
    """CLI (ì§„í–‰ ìƒí™© ì¶”ê°€)"""

    def start_book_session(self, ...):
        """ì±… ìƒì„± ì„¸ì…˜ (ì§„í–‰ ë°” ì¶”ê°€)"""

        # ì§„í–‰ ë°” ì´ˆê¸°í™”
        tracker = ProgressTracker()
        tracker.start()

        book_task = tracker.add_book_task(topic, estimated_chapters)
        current_chapter_task = None

        try:
            for event in self.app.stream(initial_state, config, stream_mode="values"):
                # í˜„ì¬ ë‹¨ê³„ ê°ì§€
                current_stage = event.get("current_stage")
                chapter_number = event.get("chapter_number", 0)

                # ìƒˆ ì±•í„° ì‹œì‘
                if current_stage == "writing_chapter" and current_chapter_task is None:
                    current_chapter_task = tracker.add_chapter_task(chapter_number)

                # ì—ì´ì „íŠ¸ ì§„í–‰
                if current_stage and "node:" in current_stage:
                    agent_name = current_stage.split(":")[1]
                    tracker.update_chapter(chapter_number, agent_name)

                # ì±•í„° ì™„ë£Œ
                if chapter_number in event.get("completed_chapters", []):
                    tracker.complete_chapter(chapter_number)
                    current_chapter_task = None

        finally:
            tracker.stop()
```

**ì¶œë ¥ ì˜ˆ**:
```
ğŸ“š ì• í”Œì˜ ì—­ì‚¬ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 80% (2/3 chapters)
  ğŸ“ Chapter 2 - Editor â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%
  ğŸ“ Chapter 3 - Writer â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 40%
```

---

### 5. ìë™ ì„¸ì…˜ ì¬ê°œ

#### íŒŒì¼: `src/utils/session_manager.py` (ì‹ ê·œ)

```python
import json
from pathlib import Path
from typing import Optional, Dict, List
from datetime import datetime

class SessionManager:
    """ì„¸ì…˜ ê´€ë¦¬"""

    def __init__(self, sessions_dir: str = "data/sessions"):
        self.sessions_dir = Path(sessions_dir)
        self.sessions_dir.mkdir(parents=True, exist_ok=True)

    def save_session_info(
        self,
        thread_id: str,
        topic: str,
        mode: str,
        book_type: Optional[str] = None,
        chapters: Optional[int] = None
    ):
        """ì„¸ì…˜ ì •ë³´ ì €ì¥"""
        session_file = self.sessions_dir / f"{thread_id}.json"

        session_data = {
            "thread_id": thread_id,
            "topic": topic,
            "mode": mode,
            "book_type": book_type,
            "chapters": chapters,
            "created_at": datetime.now().isoformat(),
            "last_updated": datetime.now().isoformat()
        }

        with open(session_file, 'w', encoding='utf-8') as f:
            json.dump(session_data, f, ensure_ascii=False, indent=2)

    def get_latest_session(self) -> Optional[Dict]:
        """ìµœê·¼ ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸°"""
        session_files = list(self.sessions_dir.glob("*.json"))

        if not session_files:
            return None

        # ìµœê·¼ íŒŒì¼
        latest_file = max(session_files, key=lambda p: p.stat().st_mtime)

        with open(latest_file, 'r', encoding='utf-8') as f:
            return json.load(f)

    def list_sessions(self, limit: int = 10) -> List[Dict]:
        """ì„¸ì…˜ ëª©ë¡"""
        session_files = sorted(
            self.sessions_dir.glob("*.json"),
            key=lambda p: p.stat().st_mtime,
            reverse=True
        )[:limit]

        sessions = []
        for file in session_files:
            with open(file, 'r', encoding='utf-8') as f:
                sessions.append(json.load(f))

        return sessions
```

#### ì ìš©: main.py

```python
# main.py

from src.utils.session_manager import SessionManager

def main():
    parser = argparse.ArgumentParser(...)

    # ìë™ ì¬ê°œ ì˜µì…˜ ì¶”ê°€
    parser.add_argument(
        "--resume",
        action="store_true",
        help="Resume latest session automatically"
    )

    args = parser.parse_args()

    session_manager = SessionManager()

    # ìë™ ì¬ê°œ
    if args.resume and not args.thread_id:
        latest = session_manager.get_latest_session()

        if latest:
            print(f"ğŸ“‚ Resuming latest session:")
            print(f"   Topic: {latest['topic']}")
            print(f"   Mode: {latest['mode']}")
            print(f"   Created: {latest['created_at']}")
            print()

            args.thread_id = latest["thread_id"]
            args.topic = latest.get("topic")
            args.mode = latest.get("mode", "multi-agent")
        else:
            print("âš ï¸  No previous sessions found")
            sys.exit(1)

    # CLI ì‹¤í–‰
    try:
        cli = CLI(mode=args.mode)

        # ì„¸ì…˜ ì •ë³´ ì €ì¥
        if not args.thread_id:
            thread_id = str(uuid.uuid4())
            session_manager.save_session_info(
                thread_id=thread_id,
                topic=args.topic,
                mode=args.mode,
                book_type=args.book_type,
                chapters=args.chapters
            )
        ...
```

**ì‚¬ìš© ì˜ˆ**:
```bash
# ìë™ìœ¼ë¡œ ìµœê·¼ ì„¸ì…˜ ì¬ê°œ
python main.py --resume

# ì„¸ì…˜ ëª©ë¡ ë³´ê¸°
python main.py --list-sessions
```

---

## ê¸°ëŠ¥ í™•ì¥

### 6. ì´ë¯¸ì§€ ìƒì„± í†µí•©

#### íŒŒì¼: `src/tools/image_generator.py` (ì‹ ê·œ)

```python
from typing import Optional, List
import requests
from pathlib import Path

class ImageGenerator:
    """ì´ë¯¸ì§€ ìƒì„± (DALL-E, Stable Diffusion ë“±)"""

    def __init__(self, provider: str = "stability", api_key: Optional[str] = None):
        """
        Args:
            provider: 'openai' (DALL-E), 'stability' (Stable Diffusion)
            api_key: API í‚¤
        """
        self.provider = provider
        self.api_key = api_key

    def generate_image(
        self,
        prompt: str,
        size: str = "1024x1024",
        style: str = "natural"
    ) -> str:
        """
        ì´ë¯¸ì§€ ìƒì„±.

        Args:
            prompt: ì´ë¯¸ì§€ ì„¤ëª…
            size: í¬ê¸°
            style: ìŠ¤íƒ€ì¼

        Returns:
            ìƒì„±ëœ ì´ë¯¸ì§€ URL ë˜ëŠ” ë¡œì»¬ ê²½ë¡œ
        """
        if self.provider == "openai":
            return self._generate_with_openai(prompt, size)
        elif self.provider == "stability":
            return self._generate_with_stability(prompt, size)
        else:
            raise ValueError(f"Unknown provider: {self.provider}")

    def _generate_with_openai(self, prompt: str, size: str) -> str:
        """DALL-Eë¡œ ìƒì„±"""
        from openai import OpenAI

        client = OpenAI(api_key=self.api_key)

        response = client.images.generate(
            model="dall-e-3",
            prompt=prompt,
            size=size,
            quality="standard",
            n=1
        )

        return response.data[0].url

    def _generate_with_stability(self, prompt: str, size: str) -> str:
        """Stable Diffusionìœ¼ë¡œ ìƒì„±"""
        # Stability AI API í˜¸ì¶œ
        # ...
        pass
```

#### ì—ì´ì „íŠ¸: Image Generator Agent

**íŒŒì¼**: `src/agents/image_generator_agent.py` (ì‹ ê·œ)

```python
class ImageGeneratorAgent:
    """ì´ë¯¸ì§€ ìƒì„± ì—ì´ì „íŠ¸"""

    def __init__(self, generator: ImageGenerator):
        self.generator = generator

    def identify_image_needs(self, draft: str, outline: dict) -> List[Dict]:
        """
        ì´ˆì•ˆì—ì„œ ì´ë¯¸ì§€ê°€ í•„ìš”í•œ ë¶€ë¶„ ì‹ë³„.

        Returns:
            [
                {
                    "section": "Introduction",
                    "description": "Company timeline infographic",
                    "prompt": "A clean timeline showing Apple's history from 1976 to 2020"
                },
                ...
            ]
        """
        # LLMì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ í•„ìš” ë¶€ë¶„ ì‹ë³„
        pass

    def generate_images(self, image_specs: List[Dict]) -> List[Dict]:
        """ì´ë¯¸ì§€ ìƒì„±"""
        generated = []

        for spec in image_specs:
            image_url = self.generator.generate_image(
                prompt=spec["prompt"],
                size="1024x1024"
            )

            generated.append({
                **spec,
                "image_url": image_url
            })

        return generated
```

---

### 7. ìŒì„± ì¶œë ¥ (TTS)

#### íŒŒì¼: `src/tools/text_to_speech.py` (ì‹ ê·œ)

```python
from pathlib import Path
from typing import Optional

class TextToSpeech:
    """í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜"""

    def __init__(self, provider: str = "openai", api_key: Optional[str] = None):
        self.provider = provider
        self.api_key = api_key

    def convert_to_speech(
        self,
        text: str,
        output_path: str,
        voice: str = "alloy",
        language: str = "ko"
    ) -> str:
        """
        í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜.

        Args:
            text: ë³€í™˜í•  í…ìŠ¤íŠ¸
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            voice: ìŒì„± (alloy, echo, fable, onyx, nova, shimmer)
            language: ì–¸ì–´

        Returns:
            ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        if self.provider == "openai":
            return self._convert_with_openai(text, output_path, voice)
        else:
            raise ValueError(f"Unknown provider: {self.provider}")

    def _convert_with_openai(self, text: str, output_path: str, voice: str) -> str:
        """OpenAI TTSë¡œ ë³€í™˜"""
        from openai import OpenAI

        client = OpenAI(api_key=self.api_key)

        response = client.audio.speech.create(
            model="tts-1",
            voice=voice,
            input=text
        )

        response.stream_to_file(output_path)

        return output_path

    def convert_book_to_audiobook(
        self,
        book_path: str,
        output_dir: str,
        voice: str = "alloy"
    ) -> List[str]:
        """
        ì±… ì „ì²´ë¥¼ ì˜¤ë””ì˜¤ë¶ìœ¼ë¡œ ë³€í™˜.

        ì±•í„°ë³„ë¡œ ë¶„ë¦¬ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„±.
        """
        import re

        with open(book_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # ì±•í„°ë³„ë¡œ ë¶„ë¦¬
        chapters = re.split(r'^#\s+Chapter\s+\d+', content, flags=re.MULTILINE)

        audio_files = []
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        for i, chapter_text in enumerate(chapters[1:], 1):  # ì²« ë²ˆì§¸ëŠ” ì œëª©
            audio_file = output_path / f"chapter_{i:02d}.mp3"

            self.convert_to_speech(
                text=chapter_text,
                output_path=str(audio_file),
                voice=voice
            )

            audio_files.append(str(audio_file))

        return audio_files
```

**ì‚¬ìš© ì˜ˆ**:
```bash
# ì±…ì„ ì˜¤ë””ì˜¤ë¶ìœ¼ë¡œ ë³€í™˜
python main.py --mode book --topic "ì• í”Œì˜ ì—­ì‚¬" --chapters 3 --generate-audiobook
```

---

### 8. ë‹¤êµ­ì–´ ë²ˆì—­

#### íŒŒì¼: `src/tools/translator.py` (ì‹ ê·œ)

```python
from typing import List, Dict

class Translator:
    """ë‹¤êµ­ì–´ ë²ˆì—­"""

    def __init__(self, client):
        self.client = client

    def translate(
        self,
        text: str,
        source_lang: str,
        target_lang: str
    ) -> str:
        """
        í…ìŠ¤íŠ¸ ë²ˆì—­.

        Args:
            text: ì›ë¬¸
            source_lang: ì›ë¬¸ ì–¸ì–´ (ko, en, ja, zh)
            target_lang: ëŒ€ìƒ ì–¸ì–´

        Returns:
            ë²ˆì—­ëœ í…ìŠ¤íŠ¸
        """
        lang_names = {
            "ko": "Korean",
            "en": "English",
            "ja": "Japanese",
            "zh": "Chinese"
        }

        prompt = f"""Translate the following {lang_names[source_lang]} text to {lang_names[target_lang]}.

Maintain the original formatting, structure, and markdown syntax.

Original text:
{text}

Translated text:"""

        messages = [
            {"role": "user", "content": prompt}
        ]

        return self.client.generate(messages, temperature=0.3)

    def translate_book(
        self,
        book_path: str,
        target_lang: str,
        output_path: str
    ):
        """ì±… ì „ì²´ ë²ˆì—­"""
        with open(book_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # ì–¸ì–´ ê°ì§€
        from src.utils.language_detector import LanguageDetector
        source_lang = LanguageDetector.detect(content)

        # ë²ˆì—­
        translated = self.translate(content, source_lang, target_lang)

        # ì €ì¥
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(translated)

        return output_path
```

**ì‚¬ìš© ì˜ˆ**:
```bash
# í•œê¸€ ì±…ì„ ì˜ì–´ë¡œ ë²ˆì—­
python main.py --translate output/books/ì• í”Œì˜_ì—­ì‚¬/complete_book.md --lang en

# ì¶œë ¥: output/books/ì• í”Œì˜_ì—­ì‚¬/complete_book_en.md
```

---

## ì„±ëŠ¥ ìµœì í™”

### 9. ë³‘ë ¬ ì—ì´ì „íŠ¸ ì‹¤í–‰

í˜„ì¬ ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ìˆœì°¨ ì‹¤í–‰ë˜ì§€ë§Œ, ì¼ë¶€ëŠ” ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥:

```python
# í˜„ì¬ (ìˆœì°¨)
writer â†’ fact_check â†’ math â†’ diagram â†’ bibliography â†’ cross_ref

# ê°œì„  (ë³‘ë ¬)
writer â†’ [fact_check, math, diagram, bibliography] (ë³‘ë ¬) â†’ cross_ref
```

#### íŒŒì¼: `src/graph/workflow.py` (ìˆ˜ì •)

```python
from langgraph.graph import StateGraph, END
from langgraph.constants import Send

def create_book_workflow_parallel() -> StateGraph:
    """ì±… ì›Œí¬í”Œë¡œìš° (ë³‘ë ¬ ì²˜ë¦¬)"""

    workflow = StateGraph(WorkflowState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("writer", writer_node)
    workflow.add_node("fact_check", fact_check_node)
    workflow.add_node("math_formula", math_formula_node)
    workflow.add_node("diagram", diagram_node)
    workflow.add_node("bibliography", bibliography_node)
    workflow.add_node("cross_reference", cross_reference_node)
    workflow.add_node("editor", editor_node)

    # Writer â†’ ë³‘ë ¬ ì²˜ë¦¬ ë…¸ë“œë“¤
    def route_to_parallel_agents(state: WorkflowState):
        """Writer í›„ ë³‘ë ¬ ì—ì´ì „íŠ¸ë“¤ì—ê²Œ ë¶„ë°°"""
        return [
            Send("fact_check", state),
            Send("math_formula", state),
            Send("diagram", state),
            Send("bibliography", state)
        ]

    workflow.add_conditional_edges(
        "writer",
        route_to_parallel_agents
    )

    # ëª¨ë“  ë³‘ë ¬ ì—ì´ì „íŠ¸ â†’ Cross Reference
    workflow.add_edge("fact_check", "cross_reference")
    workflow.add_edge("math_formula", "cross_reference")
    workflow.add_edge("diagram", "cross_reference")
    workflow.add_edge("bibliography", "cross_reference")

    # Cross Reference â†’ Editor
    workflow.add_edge("cross_reference", "editor")

    return workflow
```

**ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ**: 4ê°œ ì—ì´ì „íŠ¸ë¥¼ ë³‘ë ¬ ì‹¤í–‰ ì‹œ ~4ë°° ë¹ ë¦„

---

### 10. ìºì‹± ì „ëµ

#### íŒŒì¼: `src/utils/cache.py` (ì‹ ê·œ)

```python
import hashlib
import json
from pathlib import Path
from typing import Optional, Any

class Cache:
    """ê°„ë‹¨í•œ íŒŒì¼ ê¸°ë°˜ ìºì‹œ"""

    def __init__(self, cache_dir: str = "data/cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    def _get_key(self, data: Any) -> str:
        """ë°ì´í„°ë¡œë¶€í„° ìºì‹œ í‚¤ ìƒì„±"""
        json_str = json.dumps(data, sort_keys=True)
        return hashlib.md5(json_str.encode()).hexdigest()

    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œ ì¡°íšŒ"""
        cache_file = self.cache_dir / f"{key}.json"

        if not cache_file.exists():
            return None

        with open(cache_file, 'r', encoding='utf-8') as f:
            return json.load(f)

    def set(self, key: str, value: Any, ttl: Optional[int] = None):
        """ìºì‹œ ì €ì¥"""
        cache_file = self.cache_dir / f"{key}.json"

        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(value, f, ensure_ascii=False, indent=2)

    def get_or_compute(self, key: str, compute_fn: callable) -> Any:
        """ìºì‹œ ì¡°íšŒ ë˜ëŠ” ê³„ì‚°"""
        cached = self.get(key)

        if cached is not None:
            return cached

        # ê³„ì‚°
        result = compute_fn()

        # ìºì‹œ ì €ì¥
        self.set(key, result)

        return result
```

#### ì ìš©: Web Search

```python
# src/agents/web_search_agent.py

from src.utils.cache import Cache

class WebSearchAgent:
    """Web Search Agent (ìºì‹± ì¶”ê°€)"""

    def __init__(self, provider, cache: Optional[Cache] = None):
        self.provider = provider
        self.cache = cache or Cache()

    def search_section(self, section: dict) -> List[dict]:
        """ì„¹ì…˜ ê²€ìƒ‰ (ìºì‹±)"""

        queries = section.get("search_queries", [])
        results = []

        for query in queries:
            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = self.cache._get_key({"query": query, "provider": self.provider.provider_type})

            # ìºì‹œ ì¡°íšŒ ë˜ëŠ” ê²€ìƒ‰
            result = self.cache.get_or_compute(
                cache_key,
                lambda: self.provider.search(query, max_results=5)
            )

            results.extend(result)

        return results
```

**íš¨ê³¼**: ë™ì¼í•œ ì¿¼ë¦¬ ì¬ê²€ìƒ‰ ë°©ì§€ â†’ ì†ë„ í–¥ìƒ + API ë¹„ìš© ì ˆê°

---

## í’ˆì§ˆ ë³´ì¦

### 11. í…ŒìŠ¤íŠ¸ í™•ëŒ€

#### êµ¬ì¡°
```
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_agents/
â”‚   â”‚   â”œâ”€â”€ test_writer.py
â”‚   â”‚   â”œâ”€â”€ test_editor.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ test_utils/
â”‚   â”‚   â”œâ”€â”€ test_language_detector.py
â”‚   â”‚   â”œâ”€â”€ test_context_manager.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ test_tools/
â”‚       â”œâ”€â”€ test_search_tools.py
â”‚       â””â”€â”€ ...
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ test_simple_workflow.py
â”‚   â”œâ”€â”€ test_multi_agent_workflow.py
â”‚   â””â”€â”€ test_book_workflow.py
â”œâ”€â”€ e2e/
â”‚   â”œâ”€â”€ test_book_generation.py
â”‚   â””â”€â”€ test_error_recovery.py
â””â”€â”€ fixtures/
    â”œâ”€â”€ sample_topics.py
    â””â”€â”€ mock_responses.py
```

#### ì˜ˆ: ìœ ë‹› í…ŒìŠ¤íŠ¸

**íŒŒì¼**: `tests/unit/test_utils/test_language_detector.py`

```python
import pytest
from src.utils.language_detector import LanguageDetector

class TestLanguageDetector:
    """LanguageDetector í…ŒìŠ¤íŠ¸"""

    def test_detect_korean(self):
        """í•œê¸€ ê°ì§€"""
        assert LanguageDetector.detect("ì• í”Œì˜ ì—­ì‚¬") == "ko"
        assert LanguageDetector.detect("ì•ˆë…•í•˜ì„¸ìš”") == "ko"

    def test_detect_english(self):
        """ì˜ì–´ ê°ì§€"""
        assert LanguageDetector.detect("History of Apple") == "en"
        assert LanguageDetector.detect("Hello World") == "en"

    def test_detect_japanese(self):
        """ì¼ë³¸ì–´ ê°ì§€"""
        assert LanguageDetector.detect("ã“ã‚“ã«ã¡ã¯") == "ja"
        assert LanguageDetector.detect("ã‚¢ãƒƒãƒ—ãƒ«ã®æ­´å²") == "ja"

    def test_detect_chinese(self):
        """ì¤‘êµ­ì–´ ê°ì§€"""
        assert LanguageDetector.detect("ä½ å¥½") == "zh"
        assert LanguageDetector.detect("è‹¹æœçš„å†å²") == "zh"

    def test_get_language_instruction(self):
        """ì–¸ì–´ë³„ ì§€ì‹œì‚¬í•­"""
        ko_inst = LanguageDetector.get_language_instruction("ko")
        assert "Korean" in ko_inst
        assert "í•œê¸€" in ko_inst

    def test_mixed_language_priority(self):
        """í˜¼í•© ì–¸ì–´ - ìš°ì„ ìˆœìœ„ í™•ì¸"""
        # í•œê¸€ì´ í¬í•¨ë˜ë©´ í•œê¸€
        assert LanguageDetector.detect("Apple ì• í”Œ") == "ko"
```

#### ì˜ˆ: í†µí•© í…ŒìŠ¤íŠ¸

**íŒŒì¼**: `tests/integration/test_simple_workflow.py`

```python
import pytest
from src.graph.workflow import compile_workflow, create_initial_state
from src.llm.client import LMStudioClient
from src.config.settings import settings

@pytest.mark.integration
class TestSimpleWorkflow:
    """ë‹¨ìˆœ ì›Œí¬í”Œë¡œìš° í†µí•© í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def app(self):
        """ì›Œí¬í”Œë¡œìš° ì•±"""
        return compile_workflow("simple")

    @pytest.fixture
    def config(self):
        """ì„¤ì •"""
        return {"configurable": {"thread_id": "test-session"}}

    def test_simple_workflow_runs(self, app, config):
        """ë‹¨ìˆœ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        initial_state = create_initial_state(
            topic="Test Topic",
            mode="simple",
            max_iterations=1
        )

        # ì‹¤í–‰
        events = list(app.stream(initial_state, config, stream_mode="values"))

        # ê²€ì¦
        assert len(events) > 0
        final_state = events[-1]

        assert "current_draft" in final_state
        assert len(final_state["current_draft"]) > 0

    def test_writer_editor_cycle(self, app, config):
        """Writer-Editor ì‚¬ì´í´"""
        initial_state = create_initial_state(
            topic="Artificial Intelligence",
            mode="simple",
            max_iterations=2
        )

        events = list(app.stream(initial_state, config))

        # Writer ì‹¤í–‰ í™•ì¸
        writer_events = [e for e in events if "writer" in str(e)]
        assert len(writer_events) > 0

        # Editor ì‹¤í–‰ í™•ì¸
        editor_events = [e for e in events if "editor" in str(e)]
        assert len(editor_events) > 0
```

---

## ë°°í¬ ë° ìš´ì˜

### 12. Docker ì»¨í…Œì´ë„ˆí™”

#### Dockerfile

```dockerfile
FROM python:3.10-slim

WORKDIR /app

# ì‹œìŠ¤í…œ ì˜ì¡´ì„±
RUN apt-get update && apt-get install -y \
    pandoc \
    texlive-xetex \
    && rm -rf /var/lib/apt/lists/*

# Python ì˜ì¡´ì„±
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì•± ë³µì‚¬
COPY . .

# ë°ì´í„° ë””ë ‰í† ë¦¬
RUN mkdir -p data output

ENTRYPOINT ["python", "main.py"]
```

#### docker-compose.yml

```yaml
version: '3.8'

services:
  writer-editor:
    build: .
    volumes:
      - ./data:/app/data
      - ./output:/app/output
    environment:
      - LM_STUDIO_BASE_URL=${LM_STUDIO_BASE_URL}
      - LM_STUDIO_MODEL=${LM_STUDIO_MODEL}
    command: --mode book --topic "AI History" --chapters 5

  lm-studio:
    image: lmstudio/server:latest
    ports:
      - "1234:1234"
    volumes:
      - ./models:/models
```

**ì‚¬ìš©**:
```bash
docker-compose up
```

---

### 13. CI/CD íŒŒì´í”„ë¼ì¸

#### .github/workflows/test.yml

```yaml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        pip install -e ".[dev]"

    - name: Run unit tests
      run: |
        pytest tests/unit/ -v --cov=src

    - name: Run integration tests
      run: |
        pytest tests/integration/ -v

    - name: Upload coverage
      uses: codecov/codecov-action@v3
```

---

## êµ¬í˜„ ë¡œë“œë§µ

### Phase 1: ì•ˆì •ì„± (1-2ì£¼) ğŸ”´

**ëª©í‘œ**: ì±… ìƒì„± ì‹¤íŒ¨ìœ¨ 0%

- [ ] ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ê°œì„  (`ContextManager`)
- [ ] ì–¸ì–´ ì„¤ì • ìˆ˜ì • (`LanguageDetector`)
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ê°•í™” (ì»¤ìŠ¤í…€ ì˜ˆì™¸)
- [ ] ì¬ì‹œë„ ë¡œì§ ì¶”ê°€
- [ ] í”¼ë“œë°± ë£¨í”„ ìˆ˜ì •

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] 3ì±•í„° ì±… ìƒì„± ì„±ê³µë¥  95% ì´ìƒ
- [ ] í•œê¸€ ì£¼ì œ â†’ í•œê¸€ ì¶œë ¥ 100%
- [ ] ëª¨ë¸ í¬ë˜ì‹œ ì‹œ ìë™ ë³µêµ¬ ë˜ëŠ” ëª…í™•í•œ ì•ˆë‚´

---

### Phase 2: ì‚¬ìš©ì ê²½í—˜ (2-3ì£¼) ğŸŸ¡

**ëª©í‘œ**: ì‚¬ìš©í•˜ê¸° ì‰½ê³  ì§ê´€ì ì¸ ì‹œìŠ¤í…œ

- [ ] ì§„í–‰ ìƒí™© ë°” (`ProgressTracker`)
- [ ] ì¹œì ˆí•œ ì—ëŸ¬ ë©”ì‹œì§€
- [ ] ìë™ ì„¸ì…˜ ì¬ê°œ (`SessionManager`)
- [ ] ì¤‘ê°„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
- [ ] ì›¹ ê²€ìƒ‰ í™•ì¥ (Tavily, Serper)

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] ì‚¬ìš©ìê°€ ì§„í–‰ ìƒí™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸
- [ ] ì—ëŸ¬ ë°œìƒ ì‹œ í•´ê²° ë°©ë²• ëª…í™•íˆ ì œì‹œ
- [ ] `--resume` ì˜µì…˜ìœ¼ë¡œ ê°„í¸ ì¬ê°œ

---

### Phase 3: ì„±ëŠ¥ ìµœì í™” (3-4ì£¼) ğŸŸ¡

**ëª©í‘œ**: ìƒì„± ì†ë„ 2-3ë°° í–¥ìƒ

- [ ] ë³‘ë ¬ ì—ì´ì „íŠ¸ ì‹¤í–‰
- [ ] ì»¨í…ìŠ¤íŠ¸ ì••ì¶•
- [ ] ìºì‹± ì „ëµ
- [ ] ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] 3ì±•í„° ì±… ìƒì„± ì‹œê°„ < 10ë¶„ (í˜„ì¬ ~30ë¶„)
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 50% ê°ì†Œ

---

### Phase 4: ê¸°ëŠ¥ í™•ì¥ (4-8ì£¼) ğŸŸ¢

**ëª©í‘œ**: ë©€í‹°ë¯¸ë””ì–´ ë° ë‹¤êµ­ì–´ ì§€ì›

- [ ] ì´ë¯¸ì§€ ìƒì„± í†µí•©
- [ ] ìŒì„± ì¶œë ¥ (TTS)
- [ ] ë‹¤êµ­ì–´ ë²ˆì—­
- [ ] í˜‘ì—… ëª¨ë“œ

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] ì´ë¯¸ì§€ í¬í•¨ ì±… ìƒì„±
- [ ] ì˜¤ë””ì˜¤ë¶ ìƒì„±
- [ ] í•œ â†’ ì˜, ì˜ â†’ í•œ ë²ˆì—­

---

### Phase 5: í’ˆì§ˆ ë³´ì¦ (ë³‘í–‰) ğŸŸ¢

**ëª©í‘œ**: ë†’ì€ ì½”ë“œ í’ˆì§ˆ ìœ ì§€

- [ ] ìœ ë‹› í…ŒìŠ¤íŠ¸ (ì»¤ë²„ë¦¬ì§€ 80%)
- [ ] í†µí•© í…ŒìŠ¤íŠ¸
- [ ] E2E í…ŒìŠ¤íŠ¸
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ 80% ì´ìƒ
- [ ] ëª¨ë“  PRì— ìë™ í…ŒìŠ¤íŠ¸

---

### Phase 6: ë°°í¬ (6-8ì£¼) ğŸŸ¢

**ëª©í‘œ**: í”„ë¡œë•ì…˜ ë°°í¬

- [ ] Docker ì»¨í…Œì´ë„ˆí™”
- [ ] CI/CD íŒŒì´í”„ë¼ì¸
- [ ] í´ë¼ìš°ë“œ ë°°í¬ (AWS/GCP)
- [ ] ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] `docker-compose up`ìœ¼ë¡œ ì‹¤í–‰
- [ ] ìë™ ë°°í¬ íŒŒì´í”„ë¼ì¸
- [ ] ë¡œê·¸ ë° ë©”íŠ¸ë¦­ ìˆ˜ì§‘

---

## ì˜ˆìƒ íš¨ê³¼

### ì•ˆì •ì„±
- **í˜„ì¬**: ì±… ìƒì„± ì‹¤íŒ¨ìœ¨ ~30%
- **ê°œì„  í›„**: ì±… ìƒì„± ì‹¤íŒ¨ìœ¨ <5%

### ì„±ëŠ¥
- **í˜„ì¬**: 3ì±•í„° ì±… ìƒì„± ~30ë¶„
- **ê°œì„  í›„**: 3ì±•í„° ì±… ìƒì„± <10ë¶„ (ë³‘ë ¬ ì²˜ë¦¬)

### ì‚¬ìš©ì ê²½í—˜
- **í˜„ì¬**: ì—ëŸ¬ ë°œìƒ ì‹œ í¬ê¸°ìœ¨ ë†’ìŒ
- **ê°œì„  í›„**: ìë™ ë³µêµ¬ ë˜ëŠ” ëª…í™•í•œ ê°€ì´ë“œ

### ê¸°ëŠ¥
- **í˜„ì¬**: í…ìŠ¤íŠ¸ ì „ìš©
- **ê°œì„  í›„**: ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë‹¤êµ­ì–´ ì§€ì›

---

## ê²°ë¡ 

ì´ ê°œì„  ì œì•ˆì„œëŠ” í˜„ì¬ ì‹œìŠ¤í…œì˜ ì£¼ìš” ë¬¸ì œì ì„ í•´ê²°í•˜ê³ , ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ì—¬ ë”ìš± ê°•ë ¥í•˜ê³  ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ ì‹œìŠ¤í…œìœ¼ë¡œ ë°œì „ì‹œí‚¤ëŠ” ë¡œë“œë§µì„ ì œì‹œí•©ë‹ˆë‹¤.

**ìš°ì„ ìˆœìœ„**:
1. **ì•ˆì •ì„±** (ê¸´ê¸‰) - ì±… ìƒì„± ì‹¤íŒ¨ ë°©ì§€
2. **ì‚¬ìš©ì ê²½í—˜** (ì¤‘ìš”) - ì§„í–‰ ìƒí™©, ì—ëŸ¬ ë©”ì‹œì§€
3. **ì„±ëŠ¥** (ì¤‘ìš”) - ë³‘ë ¬ ì²˜ë¦¬, ìºì‹±
4. **ê¸°ëŠ¥ í™•ì¥** (ì¼ë°˜) - ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë²ˆì—­

**ì˜ˆìƒ ê°œë°œ ê¸°ê°„**: 8-12ì£¼

**í•µì‹¬ ê°€ì¹˜**:
- âœ… **ì•ˆì •ì **: í•­ìƒ ì‘ë™í•˜ëŠ” ì‹œìŠ¤í…œ
- âœ… **ë¹ ë¦„**: ë³‘ë ¬ ì²˜ë¦¬ë¡œ 3ë°° ë¹ ë¥¸ ìƒì„±
- âœ… **ì‚¬ìš©í•˜ê¸° ì‰¬ì›€**: ì§ê´€ì ì¸ ì¸í„°í˜ì´ìŠ¤
- âœ… **í™•ì¥ ê°€ëŠ¥**: ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€ ìš©ì´

---

**ì‘ì„±ì¼**: 2025-12-28
**ë²„ì „**: 1.0
**ì‹œìŠ¤í…œ**: Writer-Editor Multi-Agent Book System
**ì‘ì„±ì**: Claude Sonnet 4.5
