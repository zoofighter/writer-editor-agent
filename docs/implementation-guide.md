# Writer-Editor ë¦¬ë·° ë£¨í”„ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ - êµ¬í˜„ ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨

1. [í”„ë¡œì íŠ¸ ê°œìš”](#í”„ë¡œì íŠ¸-ê°œìš”)
2. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
3. [í”„ë¡œì íŠ¸ êµ¬ì¡°](#í”„ë¡œì íŠ¸-êµ¬ì¡°)
4. [êµ¬í˜„ëœ ì»´í¬ë„ŒíŠ¸](#êµ¬í˜„ëœ-ì»´í¬ë„ŒíŠ¸)
5. [ë‚¨ì€ êµ¬í˜„ ì‘ì—…](#ë‚¨ì€-êµ¬í˜„-ì‘ì—…)
6. [ì‚¬ìš© ë°©ë²•](#ì‚¬ìš©-ë°©ë²•)
7. [í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸](#í•µì‹¬-í•™ìŠµ-í¬ì¸íŠ¸)

---

## í”„ë¡œì íŠ¸ ê°œìš”

### ğŸ¯ ëª©í‘œ
Writer ì—ì´ì „íŠ¸ê°€ ì´ˆì•ˆì„ ì‘ì„±í•˜ë©´ Editor ì—ì´ì „íŠ¸ê°€ í”¼ë“œë°±ì„ ì œê³µí•˜ê³ , Writerê°€ ìˆ˜ì •í•˜ëŠ” **ë¦¬ë·° ë£¨í”„ ì‹œìŠ¤í…œ** êµ¬ì¶•

### ğŸ”‘ í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸
- âœ… **ì—ì´ì „íŠ¸ ê°„ ê²€í†  ë£¨í”„(Review Loop)** íŒ¨í„´
- âœ… **ìƒíƒœ(State) ê³µìœ ** ë° ê´€ë¦¬ ë°©ë²•
- âœ… **Human-in-the-Loop** íŒ¨í„´ êµ¬í˜„

### ğŸ›  ê¸°ìˆ  ìŠ¤íƒ
- **ì–¸ì–´**: Python 3.10+
- **í”„ë ˆì„ì›Œí¬**: LangGraph
- **LLM**: ë¡œì»¬ LM Studio (Qwen ëª¨ë¸)
- **ìƒíƒœ ì €ì¥**: SQLite Checkpointer
- **UI**: Rich ê¸°ë°˜ CLI

---

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ì›Œí¬í”Œë¡œìš° íë¦„

```
START â†’ Writer â†’ Editor â†’ User Intervention â†’ [ì¡°ê±´ ë¶„ê¸°]
                                                    â†“
                                    [ê³„ì†] â”€â”€â”€â”€â”€â†’ Writer (ë£¨í”„)
                                    [ì¤‘ë‹¨] â”€â”€â”€â”€â”€â†’ END
```

### ìƒíƒœ ê´€ë¦¬ ì „ëµ

- **TypedDict** ê¸°ë°˜ ìƒíƒœ ìŠ¤í‚¤ë§ˆ
- **Reducer** íŒ¨í„´ìœ¼ë¡œ ë°˜ë³µ ì´ë ¥ ë° ëŒ€í™” ëˆ„ì 
- **SQLite Checkpointer**ë¡œ ì„¸ì…˜ ì˜ì†í™”
- **Thread ID**ë¡œ ì„¸ì…˜ ê²©ë¦¬ ë° ì¬ê°œ ì§€ì›

---

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
writer-editor-agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ settings.py           âœ… ì™„ë£Œ
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ writer.py              âœ… ì™„ë£Œ
â”‚   â”‚   â””â”€â”€ editor.py              â³ ì‘ì—… ì¤‘
â”‚   â”œâ”€â”€ graph/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ state.py               âœ… ì™„ë£Œ
â”‚   â”‚   â””â”€â”€ workflow.py            âŒ ë¯¸ì™„ë£Œ
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ client.py              âœ… ì™„ë£Œ
â”‚   â””â”€â”€ ui/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ cli.py                 âŒ ë¯¸ì™„ë£Œ
â”œâ”€â”€ tests/                         âŒ ë¯¸ì™„ë£Œ
â”œâ”€â”€ examples/                      âŒ ë¯¸ì™„ë£Œ
â”œâ”€â”€ data/
â”œâ”€â”€ docs/                          âœ… ì‘ì„± ì¤‘
â”œâ”€â”€ requirements.txt               âœ… ì™„ë£Œ
â”œâ”€â”€ pyproject.toml                 âœ… ì™„ë£Œ
â”œâ”€â”€ .env                           âœ… ì™„ë£Œ
â”œâ”€â”€ README.md                      âŒ ë¯¸ì™„ë£Œ
â””â”€â”€ main.py                        âŒ ë¯¸ì™„ë£Œ
```

---

## êµ¬í˜„ëœ ì»´í¬ë„ŒíŠ¸

### 1. í”„ë¡œì íŠ¸ ì„¤ì • íŒŒì¼

#### `requirements.txt`
```txt
langgraph>=0.2.31
langgraph-checkpoint-sqlite>=1.0.0
openai>=1.0.0
pydantic>=2.0.0
pydantic-settings>=2.0.0
rich>=13.0.0
python-dotenv>=1.0.0
```

#### `pyproject.toml`
```toml
[build-system]
requires = ["setuptools>=68.0.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "writer-editor-agent"
version = "0.1.0"
description = "Writer-Editor Review Loop Agent System with LangGraph"
requires-python = ">=3.10"
dependencies = [
    "langgraph>=0.2.31",
    "langgraph-checkpoint-sqlite>=1.0.0",
    "openai>=1.0.0",
    "pydantic>=2.0.0",
    "pydantic-settings>=2.0.0",
    "rich>=13.0.0",
    "python-dotenv>=1.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-asyncio>=0.21.0",
    "black>=23.0.0",
    "ruff>=0.1.0",
]
```

#### `.env`
```env
LM_STUDIO_BASE_URL=http://localhost:1234/v1
LM_STUDIO_MODEL=qwen
WRITER_TEMPERATURE=0.8
EDITOR_TEMPERATURE=0.3
MAX_TOKENS=2000
MAX_ITERATIONS=10
CHECKPOINT_DB_PATH=data/checkpoints.sqlite
```

---

### 2. ìƒíƒœ ìŠ¤í‚¤ë§ˆ (`src/graph/state.py`)

```python
from typing import TypedDict, List, Optional, Annotated
from operator import add

class ReviewIteration(TypedDict):
    """ë‹¨ì¼ ë¦¬ë·° ë°˜ë³µ ê¸°ë¡"""
    iteration_number: int
    draft: str
    feedback: Optional[str]
    timestamp: str

class WorkflowState(TypedDict):
    """ë©”ì¸ ì›Œí¬í”Œë¡œìš° ìƒíƒœ"""
    topic: str                                          # ì‘ì„± ì£¼ì œ
    current_draft: str                                  # í˜„ì¬ ì´ˆì•ˆ
    current_feedback: str                               # í˜„ì¬ í”¼ë“œë°±
    iterations: Annotated[List[ReviewIteration], add]   # ë°˜ë³µ ì´ë ¥ (ëˆ„ì )
    iteration_count: int                                # í˜„ì¬ ë°˜ë³µ íšŸìˆ˜
    user_decision: str                                  # ì‚¬ìš©ì ê²°ì •
    max_iterations: int                                 # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
    conversation_history: Annotated[List[dict], add]    # ëŒ€í™” ì´ë ¥ (ëˆ„ì )
```

**í•µì‹¬ ì„¤ê³„ í¬ì¸íŠ¸**:
- `Annotated[List[T], add]`: ë¦¬ìŠ¤íŠ¸ ëˆ„ì ì„ ìœ„í•œ **ë¦¬ë“€ì„œ íŒ¨í„´**
- ë…¸ë“œëŠ” ë¶€ë¶„ ìƒíƒœë§Œ ë°˜í™˜, LangGraphê°€ ìë™ ë³‘í•©
- TypedDictë¡œ íƒ€ì… ì•ˆì „ì„± í™•ë³´

---

### 3. ì„¤ì • ê´€ë¦¬ (`src/config/settings.py`)

```python
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # LM Studio ì„¤ì •
    lm_studio_base_url: str = "http://localhost:1234/v1"
    lm_studio_model: str = "qwen"

    # ìƒì„± íŒŒë¼ë¯¸í„°
    writer_temperature: float = 0.8   # ì°½ì˜ì  ê¸€ì“°ê¸°
    editor_temperature: float = 0.3   # ë¶„ì„ì  í”¼ë“œë°±
    max_tokens: int = 2000

    # ì›Œí¬í”Œë¡œìš° ì„¤ì •
    max_iterations: int = 10
    checkpoint_db_path: str = "data/checkpoints.sqlite"

    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

settings = Settings()
```

**í•µì‹¬ ì„¤ê³„ í¬ì¸íŠ¸**:
- Pydantic Settingsë¡œ í™˜ê²½ ë³€ìˆ˜ ìë™ ë¡œë“œ
- Writer(0.8)ì™€ Editor(0.3)ì— **ë‹¤ë¥¸ temperature** ì ìš©
- `.env` íŒŒì¼ë¡œ ì¤‘ì•™ ì§‘ì¤‘ì‹ ì„¤ì • ê´€ë¦¬

---

### 4. LLM í´ë¼ì´ì–¸íŠ¸ (`src/llm/client.py`)

```python
from openai import OpenAI
from typing import List, Dict, Optional

class LMStudioClient:
    """LM Studio OpenAI í˜¸í™˜ í´ë¼ì´ì–¸íŠ¸"""

    def __init__(
        self,
        base_url: str = "http://localhost:1234/v1",
        model_name: str = "qwen",
        temperature: float = 0.7,
        max_tokens: int = 2000
    ):
        self.client = OpenAI(
            base_url=base_url,
            api_key="not-needed"  # LM StudioëŠ” ì¸ì¦ ë¶ˆí•„ìš”
        )
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens

    def generate(
        self,
        messages: List[Dict[str, str]],
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None
    ) -> str:
        """LLM ìƒì„± ìš”ì²­"""
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=temperature or self.temperature,
                max_tokens=max_tokens or self.max_tokens
            )
            return response.choices[0].message.content
        except Exception as e:
            raise Exception(f"LM Studio API call failed: {e}")

    def test_connection(self) -> bool:
        """ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            self.client.models.list()
            return True
        except Exception as e:
            print(f"Connection test failed: {e}")
            return False
```

**í•µì‹¬ ì„¤ê³„ í¬ì¸íŠ¸**:
- OpenAI SDKë¥¼ ì‚¬ìš©í•œ LM Studio í†µì‹ 
- ì—°ê²° í…ŒìŠ¤íŠ¸ ê¸°ëŠ¥ ì œê³µ
- Temperature ë° max_tokens ì˜¤ë²„ë¼ì´ë“œ ì§€ì›

---

### 5. Writer ì—ì´ì „íŠ¸ (`src/agents/writer.py`)

```python
from typing import Dict, Any
from datetime import datetime
from ..llm.client import LMStudioClient
from ..graph.state import WorkflowState
from ..config.settings import settings

class WriterAgent:
    """ì´ˆì•ˆ ì‘ì„± ë° ìˆ˜ì • ì—ì´ì „íŠ¸"""

    SYSTEM_PROMPT = """You are a professional writer. Your role is to create well-structured,
engaging content based on the given topic and any feedback provided.

When writing:
- Be clear and concise
- Use proper structure (introduction, body, conclusion)
- Maintain a professional tone
- Address all feedback points if provided
- Make your content informative and engaging

Output only the draft content, no meta-commentary or explanations."""

    def __init__(self, llm_client: LMStudioClient):
        self.llm_client = llm_client

    def create_initial_draft(self, topic: str) -> str:
        """ì´ˆì•ˆ ì‘ì„±"""
        messages = [
            {"role": "system", "content": self.SYSTEM_PROMPT},
            {"role": "user", "content": f"Write a draft article about: {topic}"}
        ]
        return self.llm_client.generate(messages)

    def revise_draft(self, current_draft: str, feedback: str) -> str:
        """í”¼ë“œë°± ê¸°ë°˜ ìˆ˜ì •"""
        messages = [
            {"role": "system", "content": self.SYSTEM_PROMPT},
            {"role": "user", "content": f"""Here is the current draft:

{current_draft}

Here is the editor's feedback:

{feedback}

Please revise the draft to address all the feedback points."""}
        ]
        return self.llm_client.generate(messages)


def writer_node(state: WorkflowState) -> Dict[str, Any]:
    """LangGraph Writer ë…¸ë“œ í•¨ìˆ˜"""
    llm_client = LMStudioClient(
        base_url=settings.lm_studio_base_url,
        model_name=settings.lm_studio_model,
        temperature=settings.writer_temperature,
        max_tokens=settings.max_tokens
    )

    writer = WriterAgent(llm_client)

    # ì²« ë°˜ë³µ: ì´ˆì•ˆ ì‘ì„±
    if state["iteration_count"] == 0:
        draft = writer.create_initial_draft(state["topic"])
    else:
        # ì´í›„ ë°˜ë³µ: í”¼ë“œë°± ë°˜ì˜ ìˆ˜ì •
        draft = writer.revise_draft(
            state["current_draft"],
            state["current_feedback"]
        )

    # ë°˜ë³µ ê¸°ë¡ ìƒì„±
    iteration = {
        "iteration_number": state["iteration_count"],
        "draft": draft,
        "feedback": None,
        "timestamp": datetime.now().isoformat()
    }

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€
    message = {
        "role": "writer",
        "content": draft,
        "iteration": state["iteration_count"]
    }

    # ë¶€ë¶„ ìƒíƒœ ì—…ë°ì´íŠ¸ ë°˜í™˜
    return {
        "current_draft": draft,
        "iterations": [iteration],
        "conversation_history": [message]
    }
```

**í•µì‹¬ ì„¤ê³„ í¬ì¸íŠ¸**:
- ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ì™€ ë…¸ë“œ í•¨ìˆ˜ ë¶„ë¦¬
- ì´ˆì•ˆ ì‘ì„±ê³¼ ìˆ˜ì • ë¡œì§ ë¶„ë¦¬
- ë†’ì€ temperature(0.8)ë¡œ ì°½ì˜ì  ê¸€ì“°ê¸°

---

## ë‚¨ì€ êµ¬í˜„ ì‘ì—…

### 1. Editor ì—ì´ì „íŠ¸ (`src/agents/editor.py`)

```python
from typing import Dict, Any
from ..llm.client import LMStudioClient
from ..graph.state import WorkflowState
from ..config.settings import settings

class EditorAgent:
    """ì´ˆì•ˆ ê²€í†  ë° í”¼ë“œë°± ì—ì´ì „íŠ¸"""

    SYSTEM_PROMPT = """You are a professional editor. Your role is to review written content
and provide constructive, actionable feedback.

When reviewing:
- Evaluate clarity, structure, and flow
- Check for grammatical issues
- Suggest improvements for engagement and readability
- Be specific and actionable in your feedback
- Acknowledge what works well

Provide your feedback in a structured format:

**Strengths:**
- [List what works well]

**Areas for Improvement:**
- [Specific, actionable suggestions]

**Overall Assessment:**
[Brief summary]"""

    def __init__(self, llm_client: LMStudioClient):
        self.llm_client = llm_client

    def review_draft(self, draft: str, iteration: int) -> str:
        """ì´ˆì•ˆ ê²€í† """
        messages = [
            {"role": "system", "content": self.SYSTEM_PROMPT},
            {"role": "user", "content": f"""Please review this draft (Iteration {iteration + 1}):

{draft}

Provide your editorial feedback."""}
        ]
        return self.llm_client.generate(messages)


def editor_node(state: WorkflowState) -> Dict[str, Any]:
    """LangGraph Editor ë…¸ë“œ í•¨ìˆ˜"""
    llm_client = LMStudioClient(
        base_url=settings.lm_studio_base_url,
        model_name=settings.lm_studio_model,
        temperature=settings.editor_temperature,
        max_tokens=settings.max_tokens
    )

    editor = EditorAgent(llm_client)

    feedback = editor.review_draft(
        state["current_draft"],
        state["iteration_count"]
    )

    latest_iteration = state["iterations"][-1]
    timestamp = latest_iteration["timestamp"]

    updated_iteration = {
        "iteration_number": state["iteration_count"],
        "draft": state["current_draft"],
        "feedback": feedback,
        "timestamp": timestamp
    }

    message = {
        "role": "editor",
        "content": feedback,
        "iteration": state["iteration_count"]
    }

    return {
        "current_feedback": feedback,
        "iterations": [updated_iteration],
        "conversation_history": [message]
    }
```

---

### 2. ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ (`src/graph/workflow.py`)

```python
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.types import interrupt
from typing import Literal
from .state import WorkflowState
from ..agents.writer import writer_node
from ..agents.editor import editor_node
from ..config.settings import settings


def user_intervention_node(state: WorkflowState) -> dict:
    """ì‚¬ìš©ì ê°œì… ë…¸ë“œ - Human-in-the-Loop"""
    prompt = f"""
========================================
ITERATION {state['iteration_count'] + 1}
========================================

DRAFT:
{state['current_draft']}

{'='*40}

FEEDBACK:
{state['current_feedback'] if state['current_feedback'] else 'Not yet provided'}

{'='*40}

What would you like to do?
1. Continue to next iteration
2. Stop and accept current draft
3. Provide additional guidance

Enter your choice (continue/stop/revise):
"""

    # interrupt()ë¡œ ì‹¤í–‰ ì¤‘ë‹¨ ë° ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸°
    user_decision = interrupt(prompt)

    return {
        "user_decision": user_decision,
        "iteration_count": state["iteration_count"] + 1
    }


def should_continue(state: WorkflowState) -> Literal["writer", "end"]:
    """ì¡°ê±´ë¶€ ë¼ìš°íŒ… í•¨ìˆ˜"""
    if state["iteration_count"] >= state["max_iterations"]:
        print(f"Maximum iterations ({state['max_iterations']}) reached.")
        return "end"

    decision = state.get("user_decision", "").lower().strip()

    if decision == "stop":
        return "end"
    elif decision in ["continue", "revise"]:
        return "writer"
    else:
        return "writer"


def create_workflow() -> StateGraph:
    """ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„±"""
    workflow = StateGraph(WorkflowState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("writer", writer_node)
    workflow.add_node("editor", editor_node)
    workflow.add_node("user_intervention", user_intervention_node)

    # ì—£ì§€ ì •ì˜
    workflow.add_edge("writer", "editor")
    workflow.add_edge("editor", "user_intervention")

    # ì¡°ê±´ë¶€ ì—£ì§€
    workflow.add_conditional_edges(
        "user_intervention",
        should_continue,
        {
            "writer": "writer",
            "end": END
        }
    )

    # ì‹œì‘ì  ì„¤ì •
    workflow.set_entry_point("writer")

    return workflow


def compile_workflow():
    """ì›Œí¬í”Œë¡œìš° ì»´íŒŒì¼"""
    workflow = create_workflow()

    # SQLite ì²´í¬í¬ì¸í„° ì´ˆê¸°í™”
    checkpointer = SqliteSaver.from_conn_string(settings.checkpoint_db_path)

    # ì»´íŒŒì¼
    app = workflow.compile(checkpointer=checkpointer)

    return app
```

---

### 3. CLI ì¸í„°í˜ì´ìŠ¤ (`src/ui/cli.py`)

```python
from typing import Optional
from rich.console import Console
from rich.panel import Panel
from rich.markdown import Markdown
from rich.prompt import Prompt
from ..graph.workflow import compile_workflow
from ..config.settings import settings

console = Console()

class CLI:
    """CLI ì¸í„°í˜ì´ìŠ¤"""

    def __init__(self):
        self.app = compile_workflow()
        self.thread_id = None

    def start_session(self, topic: str, thread_id: Optional[str] = None):
        """ì„¸ì…˜ ì‹œì‘"""
        import uuid

        self.thread_id = thread_id or str(uuid.uuid4())

        config = {
            "configurable": {
                "thread_id": self.thread_id
            }
        }

        initial_state = {
            "topic": topic,
            "current_draft": "",
            "current_feedback": "",
            "iterations": [],
            "iteration_count": 0,
            "user_decision": "",
            "max_iterations": settings.max_iterations,
            "conversation_history": []
        }

        console.print(Panel(
            f"[bold green]Starting Writer-Editor Review Loop[/bold green]\\n"
            f"Topic: {topic}\\n"
            f"Thread ID: {self.thread_id}",
            title="Session Info"
        ))

        try:
            for event in self.app.stream(initial_state, config, stream_mode="values"):
                self._handle_event(event)
        except Exception as e:
            console.print(f"[bold red]Error:[/bold red] {e}")

    def _handle_event(self, event):
        """ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        if "current_draft" in event and event["current_draft"]:
            console.print(Panel(
                Markdown(event["current_draft"]),
                title=f"Draft - Iteration {event['iteration_count']}",
                border_style="blue"
            ))

        if "current_feedback" in event and event["current_feedback"]:
            console.print(Panel(
                Markdown(event["current_feedback"]),
                title=f"Feedback - Iteration {event['iteration_count']}",
                border_style="yellow"
            ))


def run_cli():
    """CLI ì‹¤í–‰"""
    cli = CLI()

    console.print("[bold blue]Writer-Editor Review Loop Agent[/bold blue]\\n")

    topic = Prompt.ask("Enter the writing topic")

    cli.start_session(topic)
```

---

### 4. ë©”ì¸ ì§„ì…ì  (`main.py`)

```python
#!/usr/bin/env python3
import argparse
from src.ui.cli import run_cli
from src.llm.client import LMStudioClient
from src.config.settings import settings


def test_lm_studio_connection():
    """LM Studio ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("Testing LM Studio connection...")
    client = LMStudioClient(
        base_url=settings.lm_studio_base_url,
        model_name=settings.lm_studio_model
    )

    if client.test_connection():
        print("âœ“ LM Studio is accessible")
        return True
    else:
        print("âœ— Cannot connect to LM Studio")
        print(f"  Make sure LM Studio is running at {settings.lm_studio_base_url}")
        return False


def main():
    parser = argparse.ArgumentParser(
        description="Writer-Editor Review Loop Agent System"
    )
    parser.add_argument(
        "--test-connection",
        action="store_true",
        help="Test LM Studio connection and exit"
    )
    parser.add_argument(
        "--topic",
        type=str,
        help="Writing topic (skips interactive prompt)"
    )
    parser.add_argument(
        "--thread-id",
        type=str,
        help="Resume previous session with thread ID"
    )

    args = parser.parse_args()

    if args.test_connection:
        test_lm_studio_connection()
        return

    if not test_lm_studio_connection():
        return

    run_cli()


if __name__ == "__main__":
    main()
```

---

## ì‚¬ìš© ë°©ë²•

### 1. í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒ í™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Windows: venv\\Scripts\\activate

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -e ".[dev]"
```

### 2. LM Studio ì„¤ì •

1. LM Studio ì‹¤í–‰
2. Qwen ëª¨ë¸ ë¡œë“œ
3. í¬íŠ¸ 1234ì—ì„œ ì„œë²„ ì‹¤í–‰ í™•ì¸

### 3. ì—°ê²° í…ŒìŠ¤íŠ¸

```bash
python main.py --test-connection
```

### 4. ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰

```bash
# ê¸°ë³¸ ì‹¤í–‰
python main.py

# ì£¼ì œ ì§€ì •
python main.py --topic "AIì˜ ë¯¸ë˜"

# ì„¸ì…˜ ì¬ê°œ
python main.py --thread-id "previous-session-id"
```

---

## í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸

### 1. ì—ì´ì „íŠ¸ ê°„ ê²€í†  ë£¨í”„ (Review Loop)

**êµ¬í˜„ ë°©ë²•**:
```python
workflow.add_conditional_edges(
    "user_intervention",
    should_continue,  # ë¼ìš°íŒ… í•¨ìˆ˜
    {"writer": "writer", "end": END}  # ë¶„ê¸° ë§µ
)
```

**í•™ìŠµ í¬ì¸íŠ¸**:
- ì¡°ê±´ë¶€ ì—£ì§€ë¡œ ë£¨í”„ ì œì–´
- ìƒíƒœë¥¼ í†µí•œ ì •ë³´ ê³µìœ 
- Writer â†’ Editor â†’ User â†’ Writer ìˆœí™˜

---

### 2. ìƒíƒœ(State) ê³µìœ  ë°©ë²•

**ë¦¬ë“€ì„œ íŒ¨í„´**:
```python
iterations: Annotated[List[ReviewIteration], add]
```

**ë™ì‘ ì›ë¦¬**:
- ê° ë…¸ë“œê°€ ìƒˆ í•­ëª©ì„ ë°˜í™˜í•˜ë©´ `add` í•¨ìˆ˜ë¡œ ëˆ„ì 
- LangGraphê°€ ìë™ìœ¼ë¡œ ê¸°ì¡´ ë¦¬ìŠ¤íŠ¸ì— ë³‘í•©
- ì „ì²´ ì´ë ¥ì„ ìœ ì§€í•˜ë©´ì„œ ê° ë…¸ë“œëŠ” ìƒˆ í•­ëª©ë§Œ ìƒì„±

---

### 3. Human-in-the-Loop íŒ¨í„´

**Interrupt ì‚¬ìš©**:
```python
# ë…¸ë“œì—ì„œ ì‹¤í–‰ ì¤‘ë‹¨
user_input = interrupt("ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ë©”ì‹œì§€")

# CLIì—ì„œ ì¬ê°œ
app.stream(Command(resume=user_input), config)
```

**ì„¸ì…˜ ê´€ë¦¬**:
```python
config = {"configurable": {"thread_id": "unique-session-id"}}
```

**í•™ìŠµ í¬ì¸íŠ¸**:
- `interrupt()`ë¡œ ì›Œí¬í”Œë¡œìš° ì¼ì‹œ ì •ì§€
- `Command(resume=...)`ë¡œ ì‚¬ìš©ì ì…ë ¥ ì „ë‹¬
- thread_idë¡œ ì„¸ì…˜ ê²©ë¦¬ ë° ì¬ê°œ

---

## ë‹¤ìŒ ë‹¨ê³„

### ì¦‰ì‹œ êµ¬í˜„ í•„ìš”
1. âœ… Editor ì—ì´ì „íŠ¸ ì™„ì„±
2. âœ… ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ êµ¬í˜„
3. âœ… CLI ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
4. âœ… ë©”ì¸ ì§„ì…ì  ì‘ì„±
5. âœ… `__init__.py` íŒŒì¼ ì‘ì„±

### ì„ íƒì  ê°œì„ 
- í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„±
- README.md ì‘ì„±
- ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- ì›¹ UI ì¶”ê°€
- ë¶„ì„ ê¸°ëŠ¥ ì¶”ê°€

---

## ì°¸ê³  ìë£Œ

- [LangGraph ê³µì‹ ë¬¸ì„œ](https://langchain-ai.github.io/langgraph/)
- [LangGraph Human-in-the-Loop](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/wait-user-input/)
- [LM Studio ê°œë°œì ë¬¸ì„œ](https://lmstudio.ai/docs/developer)
- [LangGraph ìƒíƒœ ê´€ë¦¬ ê°€ì´ë“œ](https://deepwiki.com/langchain-ai/langgraph-101/3.1-state-management)

---

**ì‘ì„±ì¼**: 2025-12-27
**ë²„ì „**: 0.1.0
**ìƒíƒœ**: êµ¬í˜„ ì§„í–‰ ì¤‘ (ì•½ 60% ì™„ë£Œ)
